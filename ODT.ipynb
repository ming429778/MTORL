{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6450,"status":"ok","timestamp":1690277693207,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"6Gz0U_qjFwGo","outputId":"04eb9058-b9be-4576-aca9-00a8db209f72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on the GPU\n"]}],"source":["import torch\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n","    print(\"Running on the GPU\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"Running on the CPU\")\n","# torch.cuda.device_count()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16590,"status":"ok","timestamp":1690277709795,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"iUskdx--FylS","outputId":"bd2e5eec-a1db-4c07-80ef-c88536c1d4a0"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3586,"status":"ok","timestamp":1690277713379,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"YutLZjOSFwGp"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","Data = pd.read_csv('kuairand_sequence.csv',index_col=0)\n","# data['user_id'].value_counts()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1690277713379,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"Yos-lPpPFwGq","outputId":"cccd95d0-9032-476d-f0de-bceb35c16100"},"outputs":[{"name":"stdout","output_type":"stream","text":["(6051,)\n","27\n"]}],"source":["import torch\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import random\n","from torch.utils.data import Dataset, DataLoader,TensorDataset\n","\n","max_length = 100\n","num_user = len(Data['user_id'].unique())\n","state_feature = len(Data.columns) - 1\n","action_feature = 3\n","\n","uid = Data['user_id'].unique()\n","uid\n","print(uid.shape)\n","print(state_feature)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6288,"status":"ok","timestamp":1690277719665,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"7fFNieKBFwGq","outputId":"40925433-af5a-47b9-94db-7e00958a3a32"},"outputs":[{"name":"stdout","output_type":"stream","text":["6051\n","6051\n","6051\n","(6051, 100)\n"]}],"source":["State = np.zeros(((num_user,max_length,state_feature)))\n","Action = np.zeros((num_user,max_length,action_feature))\n","Click = np.zeros((num_user,max_length))\n","\n","j = 0\n","for i in uid:\n","    state_sequence = np.array(Data[Data['user_id']==i])[:-1]\n","    # state_sequence = np.array(data[data['user_id']==i].drop(['short','mid','long'],axis=1))\n","    action_sequence = np.array(Data[Data['user_id']==i][['short','mid','long']])[1:]\n","    click_sequence = np.array(Data[Data['user_id']==i]['is_click'])[1:]\n","    # action_sequence = np.array(data[data['user_id']==i][['short','mid','long']])\n","    # print(action_sequence)\n","    state = np.pad(state_sequence,((0,max_length-len(state_sequence)),(0,0)))[:,1:]\n","    action = np.pad(action_sequence,((0,max_length-len(action_sequence)),(0,0)))\n","    click = np.pad(click_sequence,((0,max_length-len(click_sequence))))\n","    # print(click)\n","    State[j] = state\n","    Action[j] = action\n","    Click[j] = click\n","    j += 1\n","print(len(State))\n","print(len(Action))\n","print(len(Click))\n","print(Click.shape)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3248,"status":"ok","timestamp":1690277722904,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"Jo6KauF_FwGq","outputId":"9bf30ef4-ae06-484e-b9ae-006c03fb4222"},"outputs":[{"name":"stdout","output_type":"stream","text":["4000\n"]}],"source":["length = 20\n","max_number_traj = 4000\n","\n","number_traj = 0\n","def Select_trajectory(X,Y,Z,number_traj):\n","    Select_states = []\n","    Select_actions = []\n","    Select_clicks = []\n","    # for s in range(number_traj):\n","    while True:\n","        i = random.randint(0,len(X)-1)\n","        select_state = X[i]\n","        select_action = Y[i]\n","        select_click = Z[i]\n","        # print(select_state)\n","        # print(select_action)\n","        for k in range(0,max_length):\n","            # print(select_episode[k])\n","            if select_state[k].any() == 0:\n","                max_episode_length = k\n","                break\n","        # print(k)\n","        # print(max_episode_length)\n","        if max_episode_length >= length + 1:\n","            j = random.randint(0,max_episode_length-length-1)\n","            select_state = select_state[j:j+length]\n","            select_action = select_action[j:j+length]\n","            select_click = select_click[j:j+length]\n","            Select_states.append(select_state)\n","            Select_actions.append(select_action)\n","            Select_clicks.append(select_click)\n","            number_traj += 1\n","        # print(select_trajectory)\n","        if number_traj == max_number_traj:\n","            break\n","    return np.array(Select_states),np.array(Select_actions),np.array(Select_clicks)\n","\n","X , Y , Z = Select_trajectory(State,Action,Click,number_traj)\n","print(len(X))"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1690277722904,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"_qWsDpMDFwGq"},"outputs":[],"source":["np.random.seed(2023)\n","per = np.random.permutation(X.shape[0])\n","# print(per)\n","X = X[per]\n","Y = Y[per]\n","Z = Z[per]\n","# print(sum(Y))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":557,"status":"ok","timestamp":1690277723459,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"xo1ABK5CFwGr","outputId":"9815d067-3024-43c0-fe76-a8ff05a46628"},"outputs":[{"name":"stdout","output_type":"stream","text":["3200\n","(tensor([[0.6522, 0.9785, 0.0000, 0.0000, 0.0762, 0.0000, 1.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6522, 0.9786, 0.0000, 0.0000, 0.0814, 1.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6522, 0.9786, 0.0000, 0.0000, 0.1005, 0.0000, 1.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6522, 0.9790, 0.0000, 0.0000, 0.0683, 1.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6522, 0.9791, 0.0000, 0.0000, 0.0559, 0.0000, 1.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6522, 0.9792, 0.0000, 0.0000, 0.1608, 0.0000, 0.0000, 1.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6522, 0.9793, 0.0000, 0.0000, 0.0634, 0.0000, 1.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6522, 0.9793, 0.0000, 0.0000, 0.1104, 0.0000, 0.0000, 1.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6522, 0.9796, 0.0000, 0.0000, 0.0818, 1.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6522, 0.9798, 0.0000, 0.0000, 0.0958, 0.0000, 0.0000, 1.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6522, 0.9799, 0.0000, 0.0000, 0.1330, 0.0000, 1.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6957, 0.9801, 0.0000, 0.0000, 0.0718, 0.0000, 0.0000, 1.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6957, 0.9803, 0.0000, 0.0000, 0.0776, 0.0000, 1.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6957, 0.9807, 1.0000, 1.0000, 1.1604, 0.0000, 0.0000, 1.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6957, 0.9809, 0.0000, 0.0000, 0.0707, 0.0000, 1.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6957, 0.9811, 0.0000, 0.0000, 0.0793, 1.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6957, 0.9820, 1.0000, 1.0000, 1.1151, 0.0000, 0.0000, 1.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6957, 0.9821, 0.0000, 0.0000, 0.0973, 1.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6957, 0.9822, 0.0000, 0.0000, 0.0741, 0.0000, 1.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500],\n","        [0.6957, 0.9823, 0.0000, 0.0000, 0.0912, 0.0000, 0.0000, 1.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.5000, 0.0408, 0.7946, 0.5000, 0.0000, 0.1111, 0.8653, 1.0000, 0.7500]],\n","       device='cuda:0'), tensor([[1., 0., 0.],\n","        [0., 1., 0.],\n","        [1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.],\n","        [0., 1., 0.],\n","        [0., 0., 1.],\n","        [1., 0., 0.],\n","        [0., 0., 1.],\n","        [0., 1., 0.],\n","        [0., 0., 1.],\n","        [0., 1., 0.],\n","        [0., 0., 1.],\n","        [0., 1., 0.],\n","        [1., 0., 0.],\n","        [0., 0., 1.],\n","        [1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.],\n","        [1., 0., 0.]], device='cuda:0'), tensor([[0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.]], device='cuda:0'))\n"]}],"source":["def split_data(State, Action, Reward, timestep, input_size, output_size):\n","\n","    # 获取训练集大小\n","    train_size = int(np.round(0.8 * X.shape[0]))\n","    print(train_size)\n","    # 划分训练集、测试集\n","    x_train = X[: train_size, :].reshape(-1, timestep,input_size)\n","    y_train = Y[: train_size].reshape(-1,timestep, output_size)\n","    z_train = Z[: train_size].reshape(-1,timestep, 1)\n","\n","    x_test = X[train_size:, :].reshape(-1, timestep,input_size)\n","    y_test = Y[train_size:].reshape(-1,timestep, output_size)\n","    z_test = Z[train_size:].reshape(-1,timestep, 1)\n","\n","    return [x_train, y_train, z_train, x_test, y_test, z_test]\n","\n","# State, Action, Reward(is_click)\n","X1,Y1,Z1,X2,Y2,Z2=split_data(X,Y,Z,length,state_feature,action_feature)\n","# print(len(X2))\n","# print(len(X2))\n","X1,Y1=torch.from_numpy(X1).to(torch.float32).to(device),torch.from_numpy(Y1).to(torch.float32).to(device)\n","# print(Y2)\n","X2,Y2=torch.from_numpy(X2).to(torch.float32).to(device),torch.from_numpy(Y2).to(torch.float32).to(device)\n","Z1,Z2=torch.from_numpy(Z1).to(torch.float32).to(device),torch.from_numpy(Z2).to(torch.float32).to(device)\n","# X,Y=torch.from_numpy(X).to(torch.float32),torch.from_numpy(Y).to(torch.float32)\n","train_ids = TensorDataset(X1,Y1,Z1)\n","test_ids = TensorDataset(X2,Y2,Z2)\n","# data_ids = TensorDataset(X,Y)\n","# print(train_ids[12])\n","print(test_ids[0])"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1690277723459,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"QIbUXOhoFwGr","outputId":"91d31475-8edc-4242-ef9b-2324b55ec03e"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3200, 20, 27])\n"]}],"source":["print(X1.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1690277723459,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"IA6MjilvFwGr"},"outputs":[],"source":["# sz = 5\n","# mask = (torch.triu(torch.ones(sz, sz)) == 0).transpose(0,1)\n","# # print(mask)\n","# def attention(query, key, value, mask=mask, dropout=None):\n","#     \"Compute 'Scaled Dot Product Attention'\"\n","#     d_k = query.size(-1)\n","#     scores = torch.matmul(query, key.transpose(-2, -1)) / np.sqrt(d_k)\n","#     print(scores)\n","#     if mask is not None:\n","#         scores = scores.masked_fill(mask, value=torch.tensor(-1e9)) # mask步骤，用 -1e9 代表负无穷\n","#     print(scores)\n","#     p_attn = F.softmax(scores, dim = -1)\n","#     if dropout is not None:\n","#         p_attn = dropout(p_attn)\n","#     return torch.matmul(p_attn, value), p_attn\n","# a = torch.rand(5,5)\n","# print(a)\n","# print(attention(a,a,a))"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1690277723460,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"Tm3xIDOpFwGs"},"outputs":[],"source":["# X = torch.rand(2,20,5)\n","# Y = X.permute(0, 2, 1)\n","# print(Y.shape)\n","# torch.matmul(X, Y).shape\n","# # [batchsize seq hidden_size]"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1690277723460,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"qWymglYvFwGs"},"outputs":[],"source":["class OnlineDesionTransformer(torch.nn.Module):\n","    def __init__(self, feature_size, hidden_size, output_size):\n","        #构造函数里面的三个参数分别为，输入，中间隐藏层处理，以及输出层\n","        # super().__init__(state_dim, act_dim, max_length=max_length)\n","        super(OnlineDesionTransformer,self).__init__() #官方步骤\n","        # self.transformer = GPT2Model(config)\n","\n","        # self.embed_timestep = nn.Embedding(max_ep_len, hidden_size)\n","        # self.embed_return = torch.nn.Linear(1, hidden_size)\n","        # self.embed_state = torch.nn.Linear(self.state_dim, hidden_size)\n","        # self.embed_action = torch.nn.Linear(self.act_dim, hidden_size)\n","        self.sqrt_size = np.sqrt(hidden_size)\n","        self.query = nn.Linear(feature_size, hidden_size)\n","        self.key = nn.Linear(feature_size, hidden_size)\n","        self.value = nn.Linear(feature_size, hidden_size)\n","        self.embed_ln = nn.LayerNorm(hidden_size)\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.sigmoid = nn.Sigmoid()\n","        self.hidden = nn.Linear(hidden_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, output_size)\n","        self.LeakyReLU = nn.LeakyReLU()\n","        self.LayerNorm = nn.LayerNorm(hidden_size)\n","    # def attention(query, key, value, mask=mask, dropout=None):\n","    #     \"Compute 'Scaled Dot Product Attention'\"\n","    #     d_k = query.size(-1)\n","    #     scores = torch.matmul(query, key.transpose(-2, -1)) / np.sqrt(d_k)\n","    #     print(scores)\n","    #     if mask is not None:\n","    #         scores = scores.masked_fill(mask, value=torch.tensor(-1e9)) # mask步骤，用 -1e9 代表负无穷\n","    #     print(scores)\n","    #     p_attn = F.softmax(scores, dim = -1)\n","    #     if dropout is not None:\n","    #         p_attn = dropout(p_attn)\n","    #     return torch.matmul(p_attn, value), p_attn\n","\n","    # def forward(self, states, actions, rewards, returns_to_go, timesteps, attention_mask=None):  #搭建的第一个前层反馈神经网络  向前传递\n","    def forward(self, x):\n","        batch_size, seq_length= x.shape[0], x.shape[1]\n","\n","        # if attention_mask is None:\n","        #     # attention mask for GPT: 1 if can be attended to, 0 if not\n","        #     attention_mask = torch.ones((batch_size, seq_length), dtype=torch.long)\n","\n","        # embed each modality with a different head\n","        # state_embeddings = self.embed_state(states)\n","        # action_embeddings = self.embed_action(actions)\n","        # returns_embeddings = self.embed_return(returns_to_go)\n","        # time_embeddings = self.embed_timestep(timesteps)\n","\n","        # # time embeddings are treated similar to positional embeddings\n","        # state_embeddings = state_embeddings + time_embeddings\n","        # action_embeddings = action_embeddings + time_embeddings\n","        # returns_embeddings = returns_embeddings + time_embeddings\n","        query_layer = self.query(x)\n","        key_layer = self.key(x).permute(0, 2, 1)\n","        value_layer = self.value(x)\n","        # Standard Attention\n","        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n","        attention_scores = torch.matmul(query_layer, key_layer)\n","        # print(attention_scores.shape)\n","        # attention_scores = 0\n","        attention_scores = attention_scores / self.sqrt_size\n","        # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n","        # [batch_size heads seq_len seq_len] scores\n","        # [batch_size 1 1 seq_len]\n","        # attention_scores = attention_scores + attention_mask\n","        # Normalize the attention scores to probabilities.\n","\n","        mask = (torch.triu(torch.ones(seq_length, seq_length)) == 0).transpose(0,1).to(device)\n","        attention_scores = attention_scores.masked_fill(mask, value=torch.tensor(-1e9))\n","        # print(attention_scores)\n","\n","        attention_scores = F.dropout(attention_scores, p=0.2)\n","        attention_probs = self.softmax(attention_scores)\n","        # b = F.softmax(attention_scores,dim=1)\n","        # print(attention_probs)\n","        # print(b)\n","        # This is actually dropping out entire tokens to attend to, which might\n","        # seem a bit unusual, but is taken from the original Transformer paper.\n","        # attention_probs = self.attn_dropout(attention_probs)\n","        output = torch.matmul(attention_probs, value_layer)\n","\n","        # context_layer = F.dropout(context_layer, p=0.2)\n","        output = self.LeakyReLU(output)\n","        output = self.LeakyReLU(self.hidden(output))+output\n","        output = self.LayerNorm(output)\n","        output = self.LeakyReLU(self.hidden(output))+output\n","        # output = self.hidden(output)\n","        # output = self.LeakyReLU(output)\n","        output = self.fc2(output)\n","        output = self.softmax(output)\n","        return output"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1690277723460,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"8UHyybQuFwGt"},"outputs":[],"source":["Batchsize = 512\n","# data_train_loader = DataLoader(dataset=train_ids, batch_size=Batchsize, shuffle=True)\n","data_train_loader = DataLoader(dataset=train_ids, batch_size=Batchsize, shuffle=False)\n","data_test_loader = DataLoader(dataset=test_ids, batch_size=1, shuffle=False,drop_last=False)\n","# data_full_loader = DataLoader(dataset=data_ids, batch_size=1, shuffle=True)\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def shannon_entropy(x):\n","  p = x\n","  logp = torch.log2(p)\n","  # print(p)\n","  # print(logp)\n","  entropy = - torch.sum(p*logp,dim=-1)\n","  return entropy"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":503},"executionInfo":{"elapsed":40937,"status":"error","timestamp":1690277764394,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"cx4R3_NXFwGt","outputId":"f10fd830-f62b-4fde-afc5-3510ac31e068"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss of episode 0 = 22.405388\n","Loss of episode 1 = 22.263342\n","Loss of episode 2 = 22.158361\n","Loss of episode 3 = 22.108864\n","Loss of episode 4 = 22.03017\n","Loss of episode 5 = 21.69757\n","Loss of episode 6 = 21.505688\n","Loss of episode 7 = 21.465986\n","Loss of episode 8 = 21.447403\n","Loss of episode 9 = 21.43755\n","Loss of episode 10 = 21.433743\n","Loss of episode 11 = 21.431217\n","Loss of episode 12 = 21.429134\n","Loss of episode 13 = 21.427069\n","Loss of episode 14 = 21.426674\n","Loss of episode 15 = 21.423283\n","Loss of episode 16 = 21.42339\n","Loss of episode 17 = 21.421963\n","Loss of episode 18 = 21.421438\n","Loss of episode 19 = 21.41911\n","Loss of episode 20 = 21.420727\n","Loss of episode 21 = 21.41946\n","Loss of episode 22 = 21.419348\n","Loss of episode 23 = 21.417349\n","Loss of episode 24 = 21.415335\n","Loss of episode 25 = 21.416725\n","Loss of episode 26 = 21.416138\n","Loss of episode 27 = 21.415276\n","Loss of episode 28 = 21.415586\n","Loss of episode 29 = 21.414618\n","Loss of episode 30 = 21.41484\n","Loss of episode 31 = 21.414268\n","Loss of episode 32 = 21.414333\n","Loss of episode 33 = 21.414238\n","Loss of episode 34 = 21.413708\n","Loss of episode 35 = 21.414295\n","Loss of episode 36 = 21.412418\n","Loss of episode 37 = 21.41117\n","Loss of episode 38 = 21.411942\n","Loss of episode 39 = 21.412598\n","Loss of episode 40 = 21.410307\n","Loss of episode 41 = 21.411451\n","Loss of episode 42 = 21.410934\n","Loss of episode 43 = 21.410263\n","Loss of episode 44 = 21.410294\n","Loss of episode 45 = 21.409653\n","Loss of episode 46 = 21.409277\n","Loss of episode 47 = 21.407455\n","Loss of episode 48 = 21.40889\n","Loss of episode 49 = 21.407192\n","Loss of episode 50 = 21.405384\n","Loss of episode 51 = 21.408\n","Loss of episode 52 = 21.405508\n","Loss of episode 53 = 21.406479\n","Loss of episode 54 = 21.404234\n","Loss of episode 55 = 21.403778\n","Loss of episode 56 = 21.40209\n","Loss of episode 57 = 21.404629\n","Loss of episode 58 = 21.403133\n","Loss of episode 59 = 21.400593\n","Loss of episode 60 = 21.401144\n","Loss of episode 61 = 21.3973\n","Loss of episode 62 = 21.400066\n","Loss of episode 63 = 21.398132\n","Loss of episode 64 = 21.397718\n","Loss of episode 65 = 21.396627\n","Loss of episode 66 = 21.395016\n","Loss of episode 67 = 21.395422\n","Loss of episode 68 = 21.394415\n","Loss of episode 69 = 21.39182\n","Loss of episode 70 = 21.391842\n","Loss of episode 71 = 21.390676\n","Loss of episode 72 = 21.38983\n","Loss of episode 73 = 21.388264\n","Loss of episode 74 = 21.398327\n","Loss of episode 75 = 21.392935\n","Loss of episode 76 = 21.392899\n","Loss of episode 77 = 21.39131\n","Loss of episode 78 = 21.384472\n","Loss of episode 79 = 21.382467\n","Loss of episode 80 = 21.384167\n","Loss of episode 81 = 21.379843\n","Loss of episode 82 = 21.386745\n","Loss of episode 83 = 21.387653\n","Loss of episode 84 = 21.375525\n","Loss of episode 85 = 21.375565\n","Loss of episode 86 = 21.371695\n","Loss of episode 87 = 21.37341\n","Loss of episode 88 = 21.367956\n","Loss of episode 89 = 21.366795\n","Loss of episode 90 = 21.364447\n","Loss of episode 91 = 21.368591\n","Loss of episode 92 = 21.363844\n","Loss of episode 93 = 21.372856\n","Loss of episode 94 = 21.399677\n","Loss of episode 95 = 21.378874\n","Loss of episode 96 = 21.375607\n","Loss of episode 97 = 21.367804\n","Loss of episode 98 = 21.365278\n","Loss of episode 99 = 21.359848\n","Loss of episode 100 = 21.363686\n","Loss of episode 101 = 21.361006\n","Loss of episode 102 = 21.360212\n","Loss of episode 103 = 21.35459\n","Loss of episode 104 = 21.347448\n","Loss of episode 105 = 21.339567\n","Loss of episode 106 = 21.341373\n","Loss of episode 107 = 21.33928\n","Loss of episode 108 = 21.34227\n","Loss of episode 109 = 21.33757\n","Loss of episode 110 = 21.334843\n","Loss of episode 111 = 21.340618\n","Loss of episode 112 = 21.32804\n","Loss of episode 113 = 21.332678\n","Loss of episode 114 = 21.34047\n","Loss of episode 115 = 21.418066\n","Loss of episode 116 = 21.37006\n","Loss of episode 117 = 21.355177\n","Loss of episode 118 = 21.340988\n","Loss of episode 119 = 21.330925\n","Loss of episode 120 = 21.323317\n","Loss of episode 121 = 21.320608\n","Loss of episode 122 = 21.321005\n","Loss of episode 123 = 21.312963\n","Loss of episode 124 = 21.311062\n","Loss of episode 125 = 21.310314\n","Loss of episode 126 = 21.302807\n","Loss of episode 127 = 21.311033\n","Loss of episode 128 = 21.311962\n","Loss of episode 129 = 21.309559\n","Loss of episode 130 = 21.31818\n","Loss of episode 131 = 21.318428\n","Loss of episode 132 = 21.311125\n","Loss of episode 133 = 21.311123\n","Loss of episode 134 = 21.31139\n","Loss of episode 135 = 21.306992\n","Loss of episode 136 = 21.306759\n","Loss of episode 137 = 21.306694\n","Loss of episode 138 = 21.290897\n","Loss of episode 139 = 21.28346\n","Loss of episode 140 = 21.278881\n","Loss of episode 141 = 21.278334\n","Loss of episode 142 = 21.274376\n","Loss of episode 143 = 21.273727\n","Loss of episode 144 = 21.272713\n","Loss of episode 145 = 21.272282\n","Loss of episode 146 = 21.266186\n","Loss of episode 147 = 21.265018\n","Loss of episode 148 = 21.257175\n","Loss of episode 149 = 21.258049\n","Loss of episode 150 = 21.256222\n","Loss of episode 151 = 21.267286\n","Loss of episode 152 = 21.255157\n","Loss of episode 153 = 21.278143\n","Loss of episode 154 = 21.289051\n","Loss of episode 155 = 21.320906\n","Loss of episode 156 = 21.312014\n","Loss of episode 157 = 21.27708\n","Loss of episode 158 = 21.264297\n","Loss of episode 159 = 21.248135\n","Loss of episode 160 = 21.246178\n","Loss of episode 161 = 21.236145\n","Loss of episode 162 = 21.22797\n","Loss of episode 163 = 21.224354\n","Loss of episode 164 = 21.220648\n","Loss of episode 165 = 21.217373\n","Loss of episode 166 = 21.219713\n","Loss of episode 167 = 21.228107\n","Loss of episode 168 = 21.239035\n","Loss of episode 169 = 21.245369\n","Loss of episode 170 = 21.236362\n","Loss of episode 171 = 21.228836\n","Loss of episode 172 = 21.225187\n","Loss of episode 173 = 21.21082\n","Loss of episode 174 = 21.201817\n","Loss of episode 175 = 21.197891\n","Loss of episode 176 = 21.188284\n","Loss of episode 177 = 21.190983\n","Loss of episode 178 = 21.189388\n","Loss of episode 179 = 21.191166\n","Loss of episode 180 = 21.182049\n","Loss of episode 181 = 21.175657\n","Loss of episode 182 = 21.179678\n","Loss of episode 183 = 21.176609\n","Loss of episode 184 = 21.181309\n","Loss of episode 185 = 21.179064\n","Loss of episode 186 = 21.190613\n","Loss of episode 187 = 21.203865\n","Loss of episode 188 = 21.228514\n","Loss of episode 189 = 21.18055\n","Loss of episode 190 = 21.171307\n","Loss of episode 191 = 21.159657\n","Loss of episode 192 = 21.161976\n","Loss of episode 193 = 21.14565\n","Loss of episode 194 = 21.146332\n","Loss of episode 195 = 21.145807\n","Loss of episode 196 = 21.162766\n","Loss of episode 197 = 21.163086\n","Loss of episode 198 = 21.164312\n","Loss of episode 199 = 21.153124\n","Loss of episode 200 = 21.151007\n","Loss of episode 201 = 21.141125\n","Loss of episode 202 = 21.165672\n","Loss of episode 203 = 21.203537\n","Loss of episode 204 = 21.208012\n","Loss of episode 205 = 21.157997\n","Loss of episode 206 = 21.141792\n","Loss of episode 207 = 21.140621\n","Loss of episode 208 = 21.119375\n","Loss of episode 209 = 21.106441\n","Loss of episode 210 = 21.10949\n","Loss of episode 211 = 21.094933\n","Loss of episode 212 = 21.089115\n","Loss of episode 213 = 21.080706\n","Loss of episode 214 = 21.079674\n","Loss of episode 215 = 21.082806\n","Loss of episode 216 = 21.082876\n","Loss of episode 217 = 21.074146\n","Loss of episode 218 = 21.075722\n","Loss of episode 219 = 21.067854\n","Loss of episode 220 = 21.067183\n","Loss of episode 221 = 21.085434\n","Loss of episode 222 = 21.07714\n","Loss of episode 223 = 21.087477\n","Loss of episode 224 = 21.102484\n","Loss of episode 225 = 21.10865\n","Loss of episode 226 = 21.11028\n","Loss of episode 227 = 21.100471\n","Loss of episode 228 = 21.074707\n","Loss of episode 229 = 21.0644\n","Loss of episode 230 = 21.057934\n","Loss of episode 231 = 21.065521\n","Loss of episode 232 = 21.051258\n","Loss of episode 233 = 21.062828\n","Loss of episode 234 = 21.052513\n","Loss of episode 235 = 21.052979\n","Loss of episode 236 = 21.035206\n","Loss of episode 237 = 21.04773\n","Loss of episode 238 = 21.045666\n","Loss of episode 239 = 21.04478\n","Loss of episode 240 = 21.045238\n","Loss of episode 241 = 21.039925\n","Loss of episode 242 = 21.043095\n","Loss of episode 243 = 21.061699\n","Loss of episode 244 = 21.046585\n","Loss of episode 245 = 21.073128\n","Loss of episode 246 = 21.045597\n","Loss of episode 247 = 21.047096\n","Loss of episode 248 = 21.04454\n","Loss of episode 249 = 21.032032\n","Loss of episode 250 = 21.0211\n","Loss of episode 251 = 21.05582\n","Loss of episode 252 = 21.027056\n","Loss of episode 253 = 21.00417\n","Loss of episode 254 = 20.992584\n","Loss of episode 255 = 20.993553\n","Loss of episode 256 = 20.980015\n","Loss of episode 257 = 20.987595\n","Loss of episode 258 = 20.981335\n","Loss of episode 259 = 20.980433\n","Loss of episode 260 = 20.97623\n","Loss of episode 261 = 20.984985\n","Loss of episode 262 = 20.974522\n","Loss of episode 263 = 20.966124\n","Loss of episode 264 = 20.97619\n","Loss of episode 265 = 20.962065\n","Loss of episode 266 = 20.982304\n","Loss of episode 267 = 20.980778\n","Loss of episode 268 = 20.977446\n","Loss of episode 269 = 20.964926\n","Loss of episode 270 = 20.955574\n","Loss of episode 271 = 20.953747\n","Loss of episode 272 = 20.959461\n","Loss of episode 273 = 20.958664\n","Loss of episode 274 = 20.956228\n","Loss of episode 275 = 20.949986\n","Loss of episode 276 = 20.953667\n","Loss of episode 277 = 20.959492\n","Loss of episode 278 = 20.962864\n","Loss of episode 279 = 20.950352\n","Loss of episode 280 = 20.952295\n","Loss of episode 281 = 20.941229\n","Loss of episode 282 = 20.929943\n","Loss of episode 283 = 20.942612\n","Loss of episode 284 = 20.926485\n","Loss of episode 285 = 20.923912\n","Loss of episode 286 = 20.899069\n","Loss of episode 287 = 20.90506\n","Loss of episode 288 = 20.891363\n","Loss of episode 289 = 20.895844\n","Loss of episode 290 = 20.88562\n","Loss of episode 291 = 20.882786\n","Loss of episode 292 = 20.90464\n","Loss of episode 293 = 20.901794\n","Loss of episode 294 = 20.89591\n","Loss of episode 295 = 20.89579\n","Loss of episode 296 = 20.903694\n","Loss of episode 297 = 20.901768\n","Loss of episode 298 = 20.913052\n","Loss of episode 299 = 20.909225\n","Loss of episode 300 = 20.918468\n","Loss of episode 301 = 20.909151\n","Loss of episode 302 = 20.919432\n","Loss of episode 303 = 20.914795\n","Loss of episode 304 = 20.898619\n","Loss of episode 305 = 20.892206\n","Loss of episode 306 = 20.859583\n","Loss of episode 307 = 20.871702\n","Loss of episode 308 = 20.8513\n","Loss of episode 309 = 20.842224\n","Loss of episode 310 = 20.842724\n","Loss of episode 311 = 20.850248\n","Loss of episode 312 = 20.857586\n","Loss of episode 313 = 20.873297\n","Loss of episode 314 = 20.86756\n","Loss of episode 315 = 20.872017\n","Loss of episode 316 = 20.868519\n","Loss of episode 317 = 20.875666\n","Loss of episode 318 = 20.86112\n","Loss of episode 319 = 20.853971\n","Loss of episode 320 = 20.840992\n","Loss of episode 321 = 20.839762\n","Loss of episode 322 = 20.830406\n","Loss of episode 323 = 20.834518\n","Loss of episode 324 = 20.819006\n","Loss of episode 325 = 20.817879\n","Loss of episode 326 = 20.804085\n","Loss of episode 327 = 20.813108\n","Loss of episode 328 = 20.807865\n","Loss of episode 329 = 20.803156\n","Loss of episode 330 = 20.813005\n","Loss of episode 331 = 20.827559\n","Loss of episode 332 = 20.817001\n","Loss of episode 333 = 20.84626\n","Loss of episode 334 = 20.84026\n","Loss of episode 335 = 20.835682\n","Loss of episode 336 = 20.841309\n","Loss of episode 337 = 20.850775\n","Loss of episode 338 = 20.835781\n","Loss of episode 339 = 20.836912\n","Loss of episode 340 = 20.828804\n","Loss of episode 341 = 20.824373\n","Loss of episode 342 = 20.838207\n","Loss of episode 343 = 20.834387\n","Loss of episode 344 = 20.823912\n","Loss of episode 345 = 20.82624\n","Loss of episode 346 = 20.788284\n","Loss of episode 347 = 20.796085\n","Loss of episode 348 = 20.778685\n","Loss of episode 349 = 20.782145\n","Loss of episode 350 = 20.772665\n","Loss of episode 351 = 20.773048\n","Loss of episode 352 = 20.754358\n","Loss of episode 353 = 20.754665\n","Loss of episode 354 = 20.75651\n","Loss of episode 355 = 20.752619\n","Loss of episode 356 = 20.746584\n","Loss of episode 357 = 20.731808\n","Loss of episode 358 = 20.742384\n","Loss of episode 359 = 20.740036\n","Loss of episode 360 = 20.724842\n","Loss of episode 361 = 20.736197\n","Loss of episode 362 = 20.740438\n","Loss of episode 363 = 20.73468\n","Loss of episode 364 = 20.758223\n","Loss of episode 365 = 20.73758\n","Loss of episode 366 = 20.759445\n","Loss of episode 367 = 20.739584\n","Loss of episode 368 = 20.743557\n","Loss of episode 369 = 20.77012\n","Loss of episode 370 = 20.761978\n","Loss of episode 371 = 20.77931\n","Loss of episode 372 = 20.786585\n","Loss of episode 373 = 20.79462\n","Loss of episode 374 = 20.788523\n","Loss of episode 375 = 20.808357\n","Loss of episode 376 = 20.760828\n","Loss of episode 377 = 20.79269\n","Loss of episode 378 = 20.769955\n","Loss of episode 379 = 20.73633\n","Loss of episode 380 = 20.730078\n","Loss of episode 381 = 20.709356\n","Loss of episode 382 = 20.692295\n","Loss of episode 383 = 20.692081\n","Loss of episode 384 = 20.677631\n","Loss of episode 385 = 20.678669\n","Loss of episode 386 = 20.678114\n","Loss of episode 387 = 20.680555\n","Loss of episode 388 = 20.674273\n","Loss of episode 389 = 20.67205\n","Loss of episode 390 = 20.673073\n","Loss of episode 391 = 20.680384\n","Loss of episode 392 = 20.67409\n","Loss of episode 393 = 20.67723\n","Loss of episode 394 = 20.676718\n","Loss of episode 395 = 20.67159\n","Loss of episode 396 = 20.669476\n","Loss of episode 397 = 20.662092\n","Loss of episode 398 = 20.673222\n","Loss of episode 399 = 20.664581\n","Loss of episode 400 = 20.66461\n","Loss of episode 401 = 20.688583\n","Loss of episode 402 = 20.687744\n","Loss of episode 403 = 20.703007\n","Loss of episode 404 = 20.724192\n","Loss of episode 405 = 20.755877\n","Loss of episode 406 = 20.743935\n","Loss of episode 407 = 20.726608\n","Loss of episode 408 = 20.693806\n","Loss of episode 409 = 20.692198\n","Loss of episode 410 = 20.669424\n","Loss of episode 411 = 20.669193\n","Loss of episode 412 = 20.666023\n","Loss of episode 413 = 20.662533\n","Loss of episode 414 = 20.655163\n","Loss of episode 415 = 20.659943\n","Loss of episode 416 = 20.639065\n","Loss of episode 417 = 20.64463\n","Loss of episode 418 = 20.62741\n","Loss of episode 419 = 20.625813\n","Loss of episode 420 = 20.621006\n","Loss of episode 421 = 20.634705\n","Loss of episode 422 = 20.625143\n","Loss of episode 423 = 20.625284\n","Loss of episode 424 = 20.62848\n","Loss of episode 425 = 20.633766\n","Loss of episode 426 = 20.638708\n","Loss of episode 427 = 20.653444\n","Loss of episode 428 = 20.658216\n","Loss of episode 429 = 20.65923\n","Loss of episode 430 = 20.637703\n","Loss of episode 431 = 20.63828\n","Loss of episode 432 = 20.642609\n","Loss of episode 433 = 20.641935\n","Loss of episode 434 = 20.642637\n","Loss of episode 435 = 20.638523\n","Loss of episode 436 = 20.638319\n","Loss of episode 437 = 20.60582\n","Loss of episode 438 = 20.619741\n","Loss of episode 439 = 20.607046\n","Loss of episode 440 = 20.618402\n","Loss of episode 441 = 20.60555\n","Loss of episode 442 = 20.600103\n","Loss of episode 443 = 20.614105\n","Loss of episode 444 = 20.607746\n","Loss of episode 445 = 20.607323\n","Loss of episode 446 = 20.608257\n","Loss of episode 447 = 20.613846\n","Loss of episode 448 = 20.629776\n","Loss of episode 449 = 20.637236\n","Loss of episode 450 = 20.624945\n","Loss of episode 451 = 20.647306\n","Loss of episode 452 = 20.644913\n","Loss of episode 453 = 20.651558\n","Loss of episode 454 = 20.64499\n","Loss of episode 455 = 20.635452\n","Loss of episode 456 = 20.628174\n","Loss of episode 457 = 20.62822\n","Loss of episode 458 = 20.607521\n","Loss of episode 459 = 20.606003\n","Loss of episode 460 = 20.592484\n","Loss of episode 461 = 20.574293\n","Loss of episode 462 = 20.587173\n","Loss of episode 463 = 20.572758\n","Loss of episode 464 = 20.56778\n","Loss of episode 465 = 20.575066\n","Loss of episode 466 = 20.560589\n","Loss of episode 467 = 20.567904\n","Loss of episode 468 = 20.57529\n","Loss of episode 469 = 20.560574\n","Loss of episode 470 = 20.575111\n","Loss of episode 471 = 20.586143\n","Loss of episode 472 = 20.583284\n","Loss of episode 473 = 20.596844\n","Loss of episode 474 = 20.57695\n","Loss of episode 475 = 20.586784\n","Loss of episode 476 = 20.573227\n","Loss of episode 477 = 20.570799\n","Loss of episode 478 = 20.56861\n","Loss of episode 479 = 20.567657\n","Loss of episode 480 = 20.572573\n","Loss of episode 481 = 20.580826\n","Loss of episode 482 = 20.564281\n","Loss of episode 483 = 20.564222\n","Loss of episode 484 = 20.56437\n","Loss of episode 485 = 20.566967\n","Loss of episode 486 = 20.569166\n","Loss of episode 487 = 20.589647\n","Loss of episode 488 = 20.562551\n","Loss of episode 489 = 20.549301\n","Loss of episode 490 = 20.54132\n","Loss of episode 491 = 20.53407\n","Loss of episode 492 = 20.534277\n","Loss of episode 493 = 20.520042\n","Loss of episode 494 = 20.523228\n","Loss of episode 495 = 20.51957\n","Loss of episode 496 = 20.52174\n","Loss of episode 497 = 20.525764\n","Loss of episode 498 = 20.51957\n","Loss of episode 499 = 20.53129\n","Loss of episode 500 = 20.518341\n","Loss of episode 501 = 20.528301\n","Loss of episode 502 = 20.520872\n","Loss of episode 503 = 20.522718\n","Loss of episode 504 = 20.534208\n","Loss of episode 505 = 20.536463\n","Loss of episode 506 = 20.549786\n","Loss of episode 507 = 20.544178\n","Loss of episode 508 = 20.537445\n","Loss of episode 509 = 20.543224\n","Loss of episode 510 = 20.536264\n","Loss of episode 511 = 20.540915\n","Loss of episode 512 = 20.547726\n","Loss of episode 513 = 20.546293\n","Loss of episode 514 = 20.555958\n","Loss of episode 515 = 20.549328\n","Loss of episode 516 = 20.54921\n","Loss of episode 517 = 20.527472\n","Loss of episode 518 = 20.531067\n","Loss of episode 519 = 20.518269\n","Loss of episode 520 = 20.519218\n","Loss of episode 521 = 20.518291\n","Loss of episode 522 = 20.518764\n","Loss of episode 523 = 20.534388\n","Loss of episode 524 = 20.510887\n","Loss of episode 525 = 20.513168\n","Loss of episode 526 = 20.525808\n","Loss of episode 527 = 20.518915\n","Loss of episode 528 = 20.509663\n","Loss of episode 529 = 20.513515\n","Loss of episode 530 = 20.515041\n","Loss of episode 531 = 20.505993\n","Loss of episode 532 = 20.509367\n","Loss of episode 533 = 20.53318\n","Loss of episode 534 = 20.500664\n","Loss of episode 535 = 20.49626\n","Loss of episode 536 = 20.483814\n","Loss of episode 537 = 20.479557\n","Loss of episode 538 = 20.477436\n","Loss of episode 539 = 20.47366\n","Loss of episode 540 = 20.471182\n","Loss of episode 541 = 20.474834\n","Loss of episode 542 = 20.48043\n","Loss of episode 543 = 20.480843\n","Loss of episode 544 = 20.476568\n","Loss of episode 545 = 20.474073\n","Loss of episode 546 = 20.468071\n","Loss of episode 547 = 20.456266\n","Loss of episode 548 = 20.466074\n","Loss of episode 549 = 20.460625\n","Loss of episode 550 = 20.473148\n","Loss of episode 551 = 20.494923\n","Loss of episode 552 = 20.504107\n","Loss of episode 553 = 20.496206\n","Loss of episode 554 = 20.482817\n","Loss of episode 555 = 20.495586\n","Loss of episode 556 = 20.485073\n","Loss of episode 557 = 20.482784\n","Loss of episode 558 = 20.483566\n","Loss of episode 559 = 20.485851\n","Loss of episode 560 = 20.4907\n","Loss of episode 561 = 20.493572\n","Loss of episode 562 = 20.51617\n","Loss of episode 563 = 20.486282\n","Loss of episode 564 = 20.503796\n","Loss of episode 565 = 20.477358\n","Loss of episode 566 = 20.48348\n","Loss of episode 567 = 20.479181\n","Loss of episode 568 = 20.477962\n","Loss of episode 569 = 20.477219\n","Loss of episode 570 = 20.478264\n","Loss of episode 571 = 20.463911\n","Loss of episode 572 = 20.464424\n","Loss of episode 573 = 20.458046\n","Loss of episode 574 = 20.467354\n","Loss of episode 575 = 20.456291\n","Loss of episode 576 = 20.46696\n","Loss of episode 577 = 20.447386\n","Loss of episode 578 = 20.432295\n","Loss of episode 579 = 20.430962\n","Loss of episode 580 = 20.44727\n","Loss of episode 581 = 20.432774\n","Loss of episode 582 = 20.435163\n","Loss of episode 583 = 20.42723\n","Loss of episode 584 = 20.434303\n","Loss of episode 585 = 20.443813\n","Loss of episode 586 = 20.435116\n","Loss of episode 587 = 20.424335\n","Loss of episode 588 = 20.417881\n","Loss of episode 589 = 20.4243\n","Loss of episode 590 = 20.442038\n","Loss of episode 591 = 20.426495\n","Loss of episode 592 = 20.42536\n","Loss of episode 593 = 20.434679\n","Loss of episode 594 = 20.452358\n","Loss of episode 595 = 20.45987\n","Loss of episode 596 = 20.448898\n","Loss of episode 597 = 20.470797\n","Loss of episode 598 = 20.477987\n","Loss of episode 599 = 20.464062\n","Loss of episode 600 = 20.452597\n","Loss of episode 601 = 20.471207\n","Loss of episode 602 = 20.476423\n","Loss of episode 603 = 20.459988\n","Loss of episode 604 = 20.467659\n","Loss of episode 605 = 20.447926\n","Loss of episode 606 = 20.449213\n","Loss of episode 607 = 20.439302\n","Loss of episode 608 = 20.443281\n","Loss of episode 609 = 20.45132\n","Loss of episode 610 = 20.423386\n","Loss of episode 611 = 20.422863\n","Loss of episode 612 = 20.40364\n","Loss of episode 613 = 20.411234\n","Loss of episode 614 = 20.4045\n","Loss of episode 615 = 20.389988\n","Loss of episode 616 = 20.397669\n","Loss of episode 617 = 20.384909\n","Loss of episode 618 = 20.394714\n","Loss of episode 619 = 20.394075\n","Loss of episode 620 = 20.382748\n","Loss of episode 621 = 20.390263\n","Loss of episode 622 = 20.384932\n","Loss of episode 623 = 20.396425\n","Loss of episode 624 = 20.410559\n","Loss of episode 625 = 20.403744\n","Loss of episode 626 = 20.397617\n","Loss of episode 627 = 20.40702\n","Loss of episode 628 = 20.416992\n","Loss of episode 629 = 20.427128\n","Loss of episode 630 = 20.428467\n","Loss of episode 631 = 20.407673\n","Loss of episode 632 = 20.435272\n","Loss of episode 633 = 20.407963\n","Loss of episode 634 = 20.409609\n","Loss of episode 635 = 20.404272\n","Loss of episode 636 = 20.399231\n","Loss of episode 637 = 20.397306\n","Loss of episode 638 = 20.40197\n","Loss of episode 639 = 20.393452\n","Loss of episode 640 = 20.398605\n","Loss of episode 641 = 20.400969\n","Loss of episode 642 = 20.380087\n","Loss of episode 643 = 20.393833\n","Loss of episode 644 = 20.398296\n","Loss of episode 645 = 20.387455\n","Loss of episode 646 = 20.42202\n","Loss of episode 647 = 20.413698\n","Loss of episode 648 = 20.405495\n","Loss of episode 649 = 20.39407\n","Loss of episode 650 = 20.394924\n","Loss of episode 651 = 20.381897\n","Loss of episode 652 = 20.386797\n","Loss of episode 653 = 20.407032\n","Loss of episode 654 = 20.393953\n","Loss of episode 655 = 20.408821\n","Loss of episode 656 = 20.404957\n","Loss of episode 657 = 20.38519\n","Loss of episode 658 = 20.389011\n","Loss of episode 659 = 20.379555\n","Loss of episode 660 = 20.400276\n","Loss of episode 661 = 20.393034\n","Loss of episode 662 = 20.37804\n","Loss of episode 663 = 20.393375\n","Loss of episode 664 = 20.370697\n","Loss of episode 665 = 20.394527\n","Loss of episode 666 = 20.370308\n","Loss of episode 667 = 20.364344\n","Loss of episode 668 = 20.368757\n","Loss of episode 669 = 20.363667\n","Loss of episode 670 = 20.357342\n","Loss of episode 671 = 20.359222\n","Loss of episode 672 = 20.363806\n","Loss of episode 673 = 20.35629\n","Loss of episode 674 = 20.3515\n","Loss of episode 675 = 20.349403\n","Loss of episode 676 = 20.347332\n","Loss of episode 677 = 20.355194\n","Loss of episode 678 = 20.35598\n","Loss of episode 679 = 20.360088\n","Loss of episode 680 = 20.356194\n","Loss of episode 681 = 20.373413\n","Loss of episode 682 = 20.364248\n","Loss of episode 683 = 20.375597\n","Loss of episode 684 = 20.402008\n","Loss of episode 685 = 20.36868\n","Loss of episode 686 = 20.386213\n","Loss of episode 687 = 20.372915\n","Loss of episode 688 = 20.364597\n","Loss of episode 689 = 20.355263\n","Loss of episode 690 = 20.360903\n","Loss of episode 691 = 20.36287\n","Loss of episode 692 = 20.378695\n","Loss of episode 693 = 20.36272\n","Loss of episode 694 = 20.362164\n","Loss of episode 695 = 20.355055\n","Loss of episode 696 = 20.363905\n","Loss of episode 697 = 20.351088\n","Loss of episode 698 = 20.37337\n","Loss of episode 699 = 20.359625\n","Loss of episode 700 = 20.362171\n","Loss of episode 701 = 20.384178\n","Loss of episode 702 = 20.378773\n","Loss of episode 703 = 20.37774\n","Loss of episode 704 = 20.37764\n","Loss of episode 705 = 20.36193\n","Loss of episode 706 = 20.366673\n","Loss of episode 707 = 20.351927\n","Loss of episode 708 = 20.339615\n","Loss of episode 709 = 20.338184\n","Loss of episode 710 = 20.326803\n","Loss of episode 711 = 20.330368\n","Loss of episode 712 = 20.329277\n","Loss of episode 713 = 20.327192\n","Loss of episode 714 = 20.353863\n","Loss of episode 715 = 20.346043\n","Loss of episode 716 = 20.35152\n","Loss of episode 717 = 20.364855\n","Loss of episode 718 = 20.346676\n","Loss of episode 719 = 20.35345\n","Loss of episode 720 = 20.339401\n","Loss of episode 721 = 20.361393\n","Loss of episode 722 = 20.345078\n","Loss of episode 723 = 20.35408\n","Loss of episode 724 = 20.351616\n","Loss of episode 725 = 20.3432\n","Loss of episode 726 = 20.34988\n","Loss of episode 727 = 20.353462\n","Loss of episode 728 = 20.362196\n","Loss of episode 729 = 20.355465\n","Loss of episode 730 = 20.355793\n","Loss of episode 731 = 20.342031\n","Loss of episode 732 = 20.328537\n","Loss of episode 733 = 20.340216\n","Loss of episode 734 = 20.347296\n","Loss of episode 735 = 20.324818\n","Loss of episode 736 = 20.341475\n","Loss of episode 737 = 20.33164\n","Loss of episode 738 = 20.33112\n","Loss of episode 739 = 20.330982\n","Loss of episode 740 = 20.32882\n","Loss of episode 741 = 20.331152\n","Loss of episode 742 = 20.320532\n","Loss of episode 743 = 20.314846\n","Loss of episode 744 = 20.320354\n","Loss of episode 745 = 20.304958\n","Loss of episode 746 = 20.31562\n","Loss of episode 747 = 20.316624\n","Loss of episode 748 = 20.319267\n","Loss of episode 749 = 20.330572\n","Loss of episode 750 = 20.329533\n","Loss of episode 751 = 20.319103\n","Loss of episode 752 = 20.326382\n","Loss of episode 753 = 20.327436\n","Loss of episode 754 = 20.335308\n","Loss of episode 755 = 20.328636\n","Loss of episode 756 = 20.338041\n","Loss of episode 757 = 20.330938\n","Loss of episode 758 = 20.34642\n","Loss of episode 759 = 20.339699\n","Loss of episode 760 = 20.306137\n","Loss of episode 761 = 20.324081\n","Loss of episode 762 = 20.311584\n","Loss of episode 763 = 20.33316\n","Loss of episode 764 = 20.32442\n","Loss of episode 765 = 20.339844\n","Loss of episode 766 = 20.317074\n","Loss of episode 767 = 20.328068\n","Loss of episode 768 = 20.313929\n","Loss of episode 769 = 20.33408\n","Loss of episode 770 = 20.328262\n","Loss of episode 771 = 20.319145\n","Loss of episode 772 = 20.304283\n","Loss of episode 773 = 20.303228\n","Loss of episode 774 = 20.316015\n","Loss of episode 775 = 20.342854\n","Loss of episode 776 = 20.330544\n","Loss of episode 777 = 20.373585\n","Loss of episode 778 = 20.34179\n","Loss of episode 779 = 20.377594\n","Loss of episode 780 = 20.349697\n","Loss of episode 781 = 20.377216\n","Loss of episode 782 = 20.40652\n","Loss of episode 783 = 20.518753\n","Loss of episode 784 = 20.56683\n","Loss of episode 785 = 20.769361\n","Loss of episode 786 = 20.958906\n","Loss of episode 787 = 20.995497\n","Loss of episode 788 = 20.788347\n","Loss of episode 789 = 20.647253\n","Loss of episode 790 = 20.514105\n","Loss of episode 791 = 20.44125\n","Loss of episode 792 = 20.409916\n","Loss of episode 793 = 20.373936\n","Loss of episode 794 = 20.360107\n","Loss of episode 795 = 20.339527\n","Loss of episode 796 = 20.339409\n","Loss of episode 797 = 20.341003\n","Loss of episode 798 = 20.334831\n","Loss of episode 799 = 20.356594\n","Loss of episode 800 = 20.382755\n","Loss of episode 801 = 20.403276\n","Loss of episode 802 = 20.456987\n","Loss of episode 803 = 20.479193\n","Loss of episode 804 = 20.41315\n","Loss of episode 805 = 20.408\n","Loss of episode 806 = 20.509981\n","Loss of episode 807 = 20.577953\n","Loss of episode 808 = 20.577972\n","Loss of episode 809 = 20.534718\n","Loss of episode 810 = 20.529842\n","Loss of episode 811 = 20.564247\n","Loss of episode 812 = 20.409056\n","Loss of episode 813 = 20.374073\n","Loss of episode 814 = 20.428\n","Loss of episode 815 = 20.41354\n","Loss of episode 816 = 20.397915\n","Loss of episode 817 = 20.395206\n","Loss of episode 818 = 20.435427\n","Loss of episode 819 = 20.376877\n","Loss of episode 820 = 20.325893\n","Loss of episode 821 = 20.352436\n","Loss of episode 822 = 20.38515\n","Loss of episode 823 = 20.358175\n","Loss of episode 824 = 20.359882\n","Loss of episode 825 = 20.390171\n","Loss of episode 826 = 20.375694\n","Loss of episode 827 = 20.309698\n","Loss of episode 828 = 20.307554\n","Loss of episode 829 = 20.350256\n","Loss of episode 830 = 20.345524\n","Loss of episode 831 = 20.34702\n","Loss of episode 832 = 20.343658\n","Loss of episode 833 = 20.373035\n","Loss of episode 834 = 20.31617\n","Loss of episode 835 = 20.286606\n","Loss of episode 836 = 20.321772\n","Loss of episode 837 = 20.339306\n","Loss of episode 838 = 20.321974\n","Loss of episode 839 = 20.313782\n","Loss of episode 840 = 20.339134\n","Loss of episode 841 = 20.326872\n","Loss of episode 842 = 20.295708\n","Loss of episode 843 = 20.302471\n","Loss of episode 844 = 20.322361\n","Loss of episode 845 = 20.322414\n","Loss of episode 846 = 20.300245\n","Loss of episode 847 = 20.330193\n","Loss of episode 848 = 20.32154\n","Loss of episode 849 = 20.304062\n","Loss of episode 850 = 20.271517\n","Loss of episode 851 = 20.294727\n","Loss of episode 852 = 20.324545\n","Loss of episode 853 = 20.3177\n","Loss of episode 854 = 20.31584\n","Loss of episode 855 = 20.330456\n","Loss of episode 856 = 20.337856\n","Loss of episode 857 = 20.304453\n","Loss of episode 858 = 20.285938\n","Loss of episode 859 = 20.306099\n","Loss of episode 860 = 20.322865\n","Loss of episode 861 = 20.332077\n","Loss of episode 862 = 20.314785\n","Loss of episode 863 = 20.347641\n","Loss of episode 864 = 20.344856\n","Loss of episode 865 = 20.301329\n","Loss of episode 866 = 20.282856\n","Loss of episode 867 = 20.305462\n","Loss of episode 868 = 20.314146\n","Loss of episode 869 = 20.312437\n","Loss of episode 870 = 20.333546\n","Loss of episode 871 = 20.33527\n","Loss of episode 872 = 20.321375\n","Loss of episode 873 = 20.292679\n","Loss of episode 874 = 20.28323\n","Loss of episode 875 = 20.291569\n","Loss of episode 876 = 20.304125\n","Loss of episode 877 = 20.285515\n","Loss of episode 878 = 20.302338\n","Loss of episode 879 = 20.301834\n","Loss of episode 880 = 20.282478\n","Loss of episode 881 = 20.256742\n","Loss of episode 882 = 20.275095\n","Loss of episode 883 = 20.289349\n","Loss of episode 884 = 20.275433\n","Loss of episode 885 = 20.269817\n","Loss of episode 886 = 20.278427\n","Loss of episode 887 = 20.317854\n","Loss of episode 888 = 20.277634\n","Loss of episode 889 = 20.25134\n","Loss of episode 890 = 20.286299\n","Loss of episode 891 = 20.300789\n","Loss of episode 892 = 20.297594\n","Loss of episode 893 = 20.29716\n","Loss of episode 894 = 20.319508\n","Loss of episode 895 = 20.351181\n","Loss of episode 896 = 20.330193\n","Loss of episode 897 = 20.308117\n","Loss of episode 898 = 20.336193\n","Loss of episode 899 = 20.337406\n","Loss of episode 900 = 20.307232\n","Loss of episode 901 = 20.321001\n","Loss of episode 902 = 20.324997\n","Loss of episode 903 = 20.284935\n","Loss of episode 904 = 20.272451\n","Loss of episode 905 = 20.274227\n","Loss of episode 906 = 20.280235\n","Loss of episode 907 = 20.266727\n","Loss of episode 908 = 20.282345\n","Loss of episode 909 = 20.27408\n","Loss of episode 910 = 20.27132\n","Loss of episode 911 = 20.260746\n","Loss of episode 912 = 20.238829\n","Loss of episode 913 = 20.261417\n","Loss of episode 914 = 20.264858\n","Loss of episode 915 = 20.266096\n","Loss of episode 916 = 20.270742\n","Loss of episode 917 = 20.276796\n","Loss of episode 918 = 20.300106\n","Loss of episode 919 = 20.263142\n","Loss of episode 920 = 20.252775\n","Loss of episode 921 = 20.270905\n","Loss of episode 922 = 20.277721\n","Loss of episode 923 = 20.273726\n","Loss of episode 924 = 20.268423\n","Loss of episode 925 = 20.294731\n","Loss of episode 926 = 20.28049\n","Loss of episode 927 = 20.25666\n","Loss of episode 928 = 20.251295\n","Loss of episode 929 = 20.281982\n","Loss of episode 930 = 20.287289\n","Loss of episode 931 = 20.263327\n","Loss of episode 932 = 20.280596\n","Loss of episode 933 = 20.280666\n","Loss of episode 934 = 20.260479\n","Loss of episode 935 = 20.245745\n","Loss of episode 936 = 20.264196\n","Loss of episode 937 = 20.27104\n","Loss of episode 938 = 20.263748\n","Loss of episode 939 = 20.248398\n","Loss of episode 940 = 20.281355\n","Loss of episode 941 = 20.265234\n","Loss of episode 942 = 20.23773\n","Loss of episode 943 = 20.252693\n","Loss of episode 944 = 20.263205\n","Loss of episode 945 = 20.25607\n","Loss of episode 946 = 20.247229\n","Loss of episode 947 = 20.259377\n","Loss of episode 948 = 20.281263\n","Loss of episode 949 = 20.251589\n","Loss of episode 950 = 20.247643\n","Loss of episode 951 = 20.249006\n","Loss of episode 952 = 20.263594\n","Loss of episode 953 = 20.266268\n","Loss of episode 954 = 20.25037\n","Loss of episode 955 = 20.257475\n","Loss of episode 956 = 20.276104\n","Loss of episode 957 = 20.233421\n","Loss of episode 958 = 20.245878\n","Loss of episode 959 = 20.256657\n","Loss of episode 960 = 20.253859\n","Loss of episode 961 = 20.249722\n","Loss of episode 962 = 20.25079\n","Loss of episode 963 = 20.267422\n","Loss of episode 964 = 20.258282\n","Loss of episode 965 = 20.230854\n","Loss of episode 966 = 20.229961\n","Loss of episode 967 = 20.263054\n","Loss of episode 968 = 20.24252\n","Loss of episode 969 = 20.23861\n","Loss of episode 970 = 20.236046\n","Loss of episode 971 = 20.250774\n","Loss of episode 972 = 20.233734\n","Loss of episode 973 = 20.220177\n","Loss of episode 974 = 20.219398\n","Loss of episode 975 = 20.236824\n","Loss of episode 976 = 20.251474\n","Loss of episode 977 = 20.23101\n","Loss of episode 978 = 20.234673\n","Loss of episode 979 = 20.250462\n","Loss of episode 980 = 20.26537\n","Loss of episode 981 = 20.237755\n","Loss of episode 982 = 20.219316\n","Loss of episode 983 = 20.246124\n","Loss of episode 984 = 20.252491\n","Loss of episode 985 = 20.239796\n","Loss of episode 986 = 20.240227\n","Loss of episode 987 = 20.282063\n","Loss of episode 988 = 20.265097\n","Loss of episode 989 = 20.226435\n","Loss of episode 990 = 20.259945\n","Loss of episode 991 = 20.261425\n","Loss of episode 992 = 20.266333\n","Loss of episode 993 = 20.26807\n","Loss of episode 994 = 20.291178\n","Loss of episode 995 = 20.298996\n","Loss of episode 996 = 20.247883\n","Loss of episode 997 = 20.250305\n","Loss of episode 998 = 20.26308\n","Loss of episode 999 = 20.248436\n","Loss of episode 1000 = 20.235352\n","Loss of episode 1001 = 20.257595\n","Loss of episode 1002 = 20.244629\n","Loss of episode 1003 = 20.22525\n","Loss of episode 1004 = 20.236164\n","Loss of episode 1005 = 20.24406\n","Loss of episode 1006 = 20.230433\n","Loss of episode 1007 = 20.223509\n","Loss of episode 1008 = 20.246618\n","Loss of episode 1009 = 20.226486\n","Loss of episode 1010 = 20.217674\n","Loss of episode 1011 = 20.20662\n","Loss of episode 1012 = 20.229239\n","Loss of episode 1013 = 20.244825\n","Loss of episode 1014 = 20.221691\n","Loss of episode 1015 = 20.240627\n","Loss of episode 1016 = 20.21246\n","Loss of episode 1017 = 20.226753\n","Loss of episode 1018 = 20.207747\n","Loss of episode 1019 = 20.212002\n","Loss of episode 1020 = 20.214956\n","Loss of episode 1021 = 20.214748\n","Loss of episode 1022 = 20.212416\n","Loss of episode 1023 = 20.223274\n","Loss of episode 1024 = 20.217644\n","Loss of episode 1025 = 20.200132\n","Loss of episode 1026 = 20.21604\n","Loss of episode 1027 = 20.21775\n","Loss of episode 1028 = 20.22444\n","Loss of episode 1029 = 20.22189\n","Loss of episode 1030 = 20.21825\n","Loss of episode 1031 = 20.223112\n","Loss of episode 1032 = 20.237713\n","Loss of episode 1033 = 20.200998\n","Loss of episode 1034 = 20.19516\n","Loss of episode 1035 = 20.226135\n","Loss of episode 1036 = 20.234829\n","Loss of episode 1037 = 20.22135\n","Loss of episode 1038 = 20.233704\n","Loss of episode 1039 = 20.260101\n","Loss of episode 1040 = 20.259151\n","Loss of episode 1041 = 20.2313\n","Loss of episode 1042 = 20.239477\n","Loss of episode 1043 = 20.259842\n","Loss of episode 1044 = 20.233555\n","Loss of episode 1045 = 20.233715\n","Loss of episode 1046 = 20.24063\n","Loss of episode 1047 = 20.241014\n","Loss of episode 1048 = 20.222425\n","Loss of episode 1049 = 20.204493\n","Loss of episode 1050 = 20.221365\n","Loss of episode 1051 = 20.219261\n","Loss of episode 1052 = 20.221973\n","Loss of episode 1053 = 20.21035\n","Loss of episode 1054 = 20.232159\n","Loss of episode 1055 = 20.230768\n","Loss of episode 1056 = 20.216\n","Loss of episode 1057 = 20.247799\n","Loss of episode 1058 = 20.239166\n","Loss of episode 1059 = 20.24329\n","Loss of episode 1060 = 20.242264\n","Loss of episode 1061 = 20.24578\n","Loss of episode 1062 = 20.247978\n","Loss of episode 1063 = 20.211296\n","Loss of episode 1064 = 20.223621\n","Loss of episode 1065 = 20.226395\n","Loss of episode 1066 = 20.230488\n","Loss of episode 1067 = 20.218386\n","Loss of episode 1068 = 20.22898\n","Loss of episode 1069 = 20.249971\n","Loss of episode 1070 = 20.235394\n","Loss of episode 1071 = 20.215103\n","Loss of episode 1072 = 20.23416\n","Loss of episode 1073 = 20.254128\n","Loss of episode 1074 = 20.230772\n","Loss of episode 1075 = 20.249723\n","Loss of episode 1076 = 20.247486\n","Loss of episode 1077 = 20.228615\n","Loss of episode 1078 = 20.217123\n","Loss of episode 1079 = 20.242872\n","Loss of episode 1080 = 20.234558\n","Loss of episode 1081 = 20.237015\n","Loss of episode 1082 = 20.268576\n","Loss of episode 1083 = 20.251213\n","Loss of episode 1084 = 20.233555\n","Loss of episode 1085 = 20.230637\n","Loss of episode 1086 = 20.288626\n","Loss of episode 1087 = 20.260206\n","Loss of episode 1088 = 20.26818\n","Loss of episode 1089 = 20.306149\n","Loss of episode 1090 = 20.305933\n","Loss of episode 1091 = 20.304806\n","Loss of episode 1092 = 20.371471\n","Loss of episode 1093 = 20.477634\n","Loss of episode 1094 = 20.506592\n","Loss of episode 1095 = 20.68948\n","Loss of episode 1096 = 20.828026\n","Loss of episode 1097 = 20.790417\n","Loss of episode 1098 = 20.487411\n","Loss of episode 1099 = 20.32281\n","Loss of episode 1100 = 20.245008\n","Loss of episode 1101 = 20.232477\n","Loss of episode 1102 = 20.226564\n","Loss of episode 1103 = 20.241394\n","Loss of episode 1104 = 20.284565\n","Loss of episode 1105 = 20.376972\n","Loss of episode 1106 = 20.422707\n","Loss of episode 1107 = 20.333303\n","Loss of episode 1108 = 20.321896\n","Loss of episode 1109 = 20.375168\n","Loss of episode 1110 = 20.372726\n","Loss of episode 1111 = 20.33463\n","Loss of episode 1112 = 20.428038\n","Loss of episode 1113 = 20.37223\n","Loss of episode 1114 = 20.266825\n","Loss of episode 1115 = 20.256857\n","Loss of episode 1116 = 20.272785\n","Loss of episode 1117 = 20.244637\n","Loss of episode 1118 = 20.271162\n","Loss of episode 1119 = 20.31306\n","Loss of episode 1120 = 20.235859\n","Loss of episode 1121 = 20.21151\n","Loss of episode 1122 = 20.220852\n","Loss of episode 1123 = 20.222479\n","Loss of episode 1124 = 20.231697\n","Loss of episode 1125 = 20.235647\n","Loss of episode 1126 = 20.289227\n","Loss of episode 1127 = 20.25483\n","Loss of episode 1128 = 20.218546\n","Loss of episode 1129 = 20.236862\n","Loss of episode 1130 = 20.258194\n","Loss of episode 1131 = 20.233582\n","Loss of episode 1132 = 20.271725\n","Loss of episode 1133 = 20.269836\n","Loss of episode 1134 = 20.223568\n","Loss of episode 1135 = 20.224731\n","Loss of episode 1136 = 20.236979\n","Loss of episode 1137 = 20.222559\n","Loss of episode 1138 = 20.237469\n","Loss of episode 1139 = 20.257504\n","Loss of episode 1140 = 20.221024\n","Loss of episode 1141 = 20.192701\n","Loss of episode 1142 = 20.200977\n","Loss of episode 1143 = 20.174938\n","Loss of episode 1144 = 20.18171\n","Loss of episode 1145 = 20.199514\n","Loss of episode 1146 = 20.182394\n","Loss of episode 1147 = 20.172962\n","Loss of episode 1148 = 20.17848\n","Loss of episode 1149 = 20.182585\n","Loss of episode 1150 = 20.202452\n","Loss of episode 1151 = 20.192425\n","Loss of episode 1152 = 20.200274\n","Loss of episode 1153 = 20.222347\n","Loss of episode 1154 = 20.222929\n","Loss of episode 1155 = 20.192648\n","Loss of episode 1156 = 20.185352\n","Loss of episode 1157 = 20.223099\n","Loss of episode 1158 = 20.195171\n","Loss of episode 1159 = 20.217495\n","Loss of episode 1160 = 20.250015\n","Loss of episode 1161 = 20.186827\n","Loss of episode 1162 = 20.182554\n","Loss of episode 1163 = 20.198156\n","Loss of episode 1164 = 20.173002\n","Loss of episode 1165 = 20.16911\n","Loss of episode 1166 = 20.19225\n","Loss of episode 1167 = 20.176508\n","Loss of episode 1168 = 20.158321\n","Loss of episode 1169 = 20.174648\n","Loss of episode 1170 = 20.188286\n","Loss of episode 1171 = 20.155619\n","Loss of episode 1172 = 20.197235\n","Loss of episode 1173 = 20.21122\n","Loss of episode 1174 = 20.182503\n","Loss of episode 1175 = 20.183876\n","Loss of episode 1176 = 20.194098\n","Loss of episode 1177 = 20.179787\n","Loss of episode 1178 = 20.217129\n","Loss of episode 1179 = 20.20423\n","Loss of episode 1180 = 20.17294\n","Loss of episode 1181 = 20.216421\n","Loss of episode 1182 = 20.201408\n","Loss of episode 1183 = 20.179853\n","Loss of episode 1184 = 20.1848\n","Loss of episode 1185 = 20.199389\n","Loss of episode 1186 = 20.16063\n","Loss of episode 1187 = 20.191208\n","Loss of episode 1188 = 20.187157\n","Loss of episode 1189 = 20.17641\n","Loss of episode 1190 = 20.209618\n","Loss of episode 1191 = 20.163157\n","Loss of episode 1192 = 20.159132\n","Loss of episode 1193 = 20.173286\n","Loss of episode 1194 = 20.175182\n","Loss of episode 1195 = 20.166279\n","Loss of episode 1196 = 20.177\n","Loss of episode 1197 = 20.168133\n","Loss of episode 1198 = 20.170036\n","Loss of episode 1199 = 20.195248\n","Loss of episode 1200 = 20.16774\n","Loss of episode 1201 = 20.152555\n","Loss of episode 1202 = 20.184109\n","Loss of episode 1203 = 20.189966\n","Loss of episode 1204 = 20.177204\n","Loss of episode 1205 = 20.184265\n","Loss of episode 1206 = 20.181747\n","Loss of episode 1207 = 20.230288\n","Loss of episode 1208 = 20.222118\n","Loss of episode 1209 = 20.20811\n","Loss of episode 1210 = 20.211706\n","Loss of episode 1211 = 20.24788\n","Loss of episode 1212 = 20.223364\n","Loss of episode 1213 = 20.225739\n","Loss of episode 1214 = 20.25603\n","Loss of episode 1215 = 20.188686\n","Loss of episode 1216 = 20.175003\n","Loss of episode 1217 = 20.215658\n","Loss of episode 1218 = 20.197865\n","Loss of episode 1219 = 20.188782\n","Loss of episode 1220 = 20.203213\n","Loss of episode 1221 = 20.183783\n","Loss of episode 1222 = 20.187382\n","Loss of episode 1223 = 20.179804\n","Loss of episode 1224 = 20.180305\n","Loss of episode 1225 = 20.166477\n","Loss of episode 1226 = 20.178165\n","Loss of episode 1227 = 20.153608\n","Loss of episode 1228 = 20.18574\n","Loss of episode 1229 = 20.17812\n","Loss of episode 1230 = 20.154007\n","Loss of episode 1231 = 20.174109\n","Loss of episode 1232 = 20.191053\n","Loss of episode 1233 = 20.1657\n","Loss of episode 1234 = 20.16019\n","Loss of episode 1235 = 20.184736\n","Loss of episode 1236 = 20.158854\n","Loss of episode 1237 = 20.148941\n","Loss of episode 1238 = 20.182526\n","Loss of episode 1239 = 20.169895\n","Loss of episode 1240 = 20.145117\n","Loss of episode 1241 = 20.16316\n","Loss of episode 1242 = 20.164253\n","Loss of episode 1243 = 20.163216\n","Loss of episode 1244 = 20.170551\n","Loss of episode 1245 = 20.162865\n","Loss of episode 1246 = 20.152746\n","Loss of episode 1247 = 20.184254\n","Loss of episode 1248 = 20.156988\n","Loss of episode 1249 = 20.158497\n","Loss of episode 1250 = 20.181723\n","Loss of episode 1251 = 20.15943\n","Loss of episode 1252 = 20.14363\n","Loss of episode 1253 = 20.155924\n","Loss of episode 1254 = 20.177698\n","Loss of episode 1255 = 20.157116\n","Loss of episode 1256 = 20.16824\n","Loss of episode 1257 = 20.191486\n","Loss of episode 1258 = 20.166042\n","Loss of episode 1259 = 20.173187\n","Loss of episode 1260 = 20.157516\n","Loss of episode 1261 = 20.1562\n","Loss of episode 1262 = 20.18432\n","Loss of episode 1263 = 20.181057\n","Loss of episode 1264 = 20.147495\n","Loss of episode 1265 = 20.178322\n","Loss of episode 1266 = 20.212814\n","Loss of episode 1267 = 20.163774\n","Loss of episode 1268 = 20.163244\n","Loss of episode 1269 = 20.177792\n","Loss of episode 1270 = 20.168875\n","Loss of episode 1271 = 20.163748\n","Loss of episode 1272 = 20.151407\n","Loss of episode 1273 = 20.176382\n","Loss of episode 1274 = 20.144157\n","Loss of episode 1275 = 20.139082\n","Loss of episode 1276 = 20.152746\n","Loss of episode 1277 = 20.146603\n","Loss of episode 1278 = 20.1469\n","Loss of episode 1279 = 20.16463\n","Loss of episode 1280 = 20.172342\n","Loss of episode 1281 = 20.174444\n","Loss of episode 1282 = 20.17694\n","Loss of episode 1283 = 20.162897\n","Loss of episode 1284 = 20.15008\n","Loss of episode 1285 = 20.170673\n","Loss of episode 1286 = 20.160446\n","Loss of episode 1287 = 20.156277\n","Loss of episode 1288 = 20.189957\n","Loss of episode 1289 = 20.177595\n","Loss of episode 1290 = 20.152393\n","Loss of episode 1291 = 20.159903\n","Loss of episode 1292 = 20.156713\n","Loss of episode 1293 = 20.136934\n","Loss of episode 1294 = 20.1433\n","Loss of episode 1295 = 20.154076\n","Loss of episode 1296 = 20.133245\n","Loss of episode 1297 = 20.150335\n","Loss of episode 1298 = 20.156248\n","Loss of episode 1299 = 20.13942\n","Loss of episode 1300 = 20.169163\n","Loss of episode 1301 = 20.17218\n","Loss of episode 1302 = 20.145199\n","Loss of episode 1303 = 20.16992\n","Loss of episode 1304 = 20.195604\n","Loss of episode 1305 = 20.16244\n","Loss of episode 1306 = 20.179094\n","Loss of episode 1307 = 20.207628\n","Loss of episode 1308 = 20.15753\n","Loss of episode 1309 = 20.15107\n","Loss of episode 1310 = 20.17603\n","Loss of episode 1311 = 20.153713\n","Loss of episode 1312 = 20.16544\n","Loss of episode 1313 = 20.16296\n","Loss of episode 1314 = 20.147709\n","Loss of episode 1315 = 20.151173\n","Loss of episode 1316 = 20.166197\n","Loss of episode 1317 = 20.145844\n","Loss of episode 1318 = 20.165821\n","Loss of episode 1319 = 20.154564\n","Loss of episode 1320 = 20.125542\n","Loss of episode 1321 = 20.136646\n","Loss of episode 1322 = 20.164162\n","Loss of episode 1323 = 20.124372\n","Loss of episode 1324 = 20.1334\n","Loss of episode 1325 = 20.140724\n","Loss of episode 1326 = 20.148823\n","Loss of episode 1327 = 20.127735\n","Loss of episode 1328 = 20.148819\n","Loss of episode 1329 = 20.156286\n","Loss of episode 1330 = 20.162884\n","Loss of episode 1331 = 20.164608\n","Loss of episode 1332 = 20.14907\n","Loss of episode 1333 = 20.165146\n","Loss of episode 1334 = 20.186113\n","Loss of episode 1335 = 20.149153\n","Loss of episode 1336 = 20.172405\n","Loss of episode 1337 = 20.19407\n","Loss of episode 1338 = 20.170092\n","Loss of episode 1339 = 20.154516\n","Loss of episode 1340 = 20.205254\n","Loss of episode 1341 = 20.163448\n","Loss of episode 1342 = 20.15482\n","Loss of episode 1343 = 20.163315\n","Loss of episode 1344 = 20.138582\n","Loss of episode 1345 = 20.132732\n","Loss of episode 1346 = 20.1643\n","Loss of episode 1347 = 20.131453\n","Loss of episode 1348 = 20.116098\n","Loss of episode 1349 = 20.131674\n","Loss of episode 1350 = 20.12307\n","Loss of episode 1351 = 20.12481\n","Loss of episode 1352 = 20.13816\n","Loss of episode 1353 = 20.126106\n","Loss of episode 1354 = 20.098667\n","Loss of episode 1355 = 20.129387\n","Loss of episode 1356 = 20.133007\n","Loss of episode 1357 = 20.10336\n","Loss of episode 1358 = 20.13454\n","Loss of episode 1359 = 20.123741\n","Loss of episode 1360 = 20.131084\n","Loss of episode 1361 = 20.134594\n","Loss of episode 1362 = 20.172043\n","Loss of episode 1363 = 20.121197\n","Loss of episode 1364 = 20.141148\n","Loss of episode 1365 = 20.15416\n","Loss of episode 1366 = 20.128521\n","Loss of episode 1367 = 20.152496\n","Loss of episode 1368 = 20.16599\n","Loss of episode 1369 = 20.11993\n","Loss of episode 1370 = 20.131117\n","Loss of episode 1371 = 20.138807\n","Loss of episode 1372 = 20.138205\n","Loss of episode 1373 = 20.15052\n","Loss of episode 1374 = 20.133884\n","Loss of episode 1375 = 20.130352\n","Loss of episode 1376 = 20.145031\n","Loss of episode 1377 = 20.145634\n","Loss of episode 1378 = 20.119873\n","Loss of episode 1379 = 20.140106\n","Loss of episode 1380 = 20.146587\n","Loss of episode 1381 = 20.114506\n","Loss of episode 1382 = 20.133091\n","Loss of episode 1383 = 20.149696\n","Loss of episode 1384 = 20.127098\n","Loss of episode 1385 = 20.139402\n","Loss of episode 1386 = 20.13777\n","Loss of episode 1387 = 20.141937\n","Loss of episode 1388 = 20.145346\n","Loss of episode 1389 = 20.12677\n","Loss of episode 1390 = 20.12697\n","Loss of episode 1391 = 20.13703\n","Loss of episode 1392 = 20.12164\n","Loss of episode 1393 = 20.102903\n","Loss of episode 1394 = 20.106915\n","Loss of episode 1395 = 20.129171\n","Loss of episode 1396 = 20.107098\n","Loss of episode 1397 = 20.113037\n","Loss of episode 1398 = 20.152895\n","Loss of episode 1399 = 20.13625\n","Loss of episode 1400 = 20.115751\n","Loss of episode 1401 = 20.162922\n","Loss of episode 1402 = 20.178364\n","Loss of episode 1403 = 20.140326\n","Loss of episode 1404 = 20.159828\n","Loss of episode 1405 = 20.150772\n","Loss of episode 1406 = 20.116177\n","Loss of episode 1407 = 20.128126\n","Loss of episode 1408 = 20.13411\n","Loss of episode 1409 = 20.112574\n","Loss of episode 1410 = 20.106216\n","Loss of episode 1411 = 20.123405\n","Loss of episode 1412 = 20.100147\n","Loss of episode 1413 = 20.103561\n","Loss of episode 1414 = 20.110296\n","Loss of episode 1415 = 20.101933\n","Loss of episode 1416 = 20.125786\n","Loss of episode 1417 = 20.130573\n","Loss of episode 1418 = 20.110779\n","Loss of episode 1419 = 20.106071\n","Loss of episode 1420 = 20.125748\n","Loss of episode 1421 = 20.115211\n","Loss of episode 1422 = 20.099691\n","Loss of episode 1423 = 20.112091\n","Loss of episode 1424 = 20.107483\n","Loss of episode 1425 = 20.09433\n","Loss of episode 1426 = 20.12399\n","Loss of episode 1427 = 20.100632\n","Loss of episode 1428 = 20.126076\n","Loss of episode 1429 = 20.12204\n","Loss of episode 1430 = 20.131577\n","Loss of episode 1431 = 20.119633\n","Loss of episode 1432 = 20.128683\n","Loss of episode 1433 = 20.153543\n","Loss of episode 1434 = 20.111443\n","Loss of episode 1435 = 20.12867\n","Loss of episode 1436 = 20.152174\n","Loss of episode 1437 = 20.126022\n","Loss of episode 1438 = 20.140488\n","Loss of episode 1439 = 20.168959\n","Loss of episode 1440 = 20.157207\n","Loss of episode 1441 = 20.147911\n","Loss of episode 1442 = 20.159557\n","Loss of episode 1443 = 20.152058\n","Loss of episode 1444 = 20.171614\n","Loss of episode 1445 = 20.148031\n","Loss of episode 1446 = 20.163153\n","Loss of episode 1447 = 20.163788\n","Loss of episode 1448 = 20.15446\n","Loss of episode 1449 = 20.131691\n","Loss of episode 1450 = 20.148226\n","Loss of episode 1451 = 20.149021\n","Loss of episode 1452 = 20.124195\n","Loss of episode 1453 = 20.141298\n","Loss of episode 1454 = 20.132317\n","Loss of episode 1455 = 20.090244\n","Loss of episode 1456 = 20.11869\n","Loss of episode 1457 = 20.13816\n","Loss of episode 1458 = 20.098356\n","Loss of episode 1459 = 20.106684\n","Loss of episode 1460 = 20.126156\n","Loss of episode 1461 = 20.101221\n","Loss of episode 1462 = 20.09621\n","Loss of episode 1463 = 20.118467\n","Loss of episode 1464 = 20.108007\n","Loss of episode 1465 = 20.100737\n","Loss of episode 1466 = 20.10869\n","Loss of episode 1467 = 20.098974\n","Loss of episode 1468 = 20.114777\n","Loss of episode 1469 = 20.111183\n","Loss of episode 1470 = 20.092617\n","Loss of episode 1471 = 20.105377\n","Loss of episode 1472 = 20.132494\n","Loss of episode 1473 = 20.095325\n","Loss of episode 1474 = 20.115238\n","Loss of episode 1475 = 20.126648\n","Loss of episode 1476 = 20.120031\n","Loss of episode 1477 = 20.098303\n","Loss of episode 1478 = 20.119698\n","Loss of episode 1479 = 20.105556\n","Loss of episode 1480 = 20.112251\n","Loss of episode 1481 = 20.105087\n","Loss of episode 1482 = 20.103514\n","Loss of episode 1483 = 20.113214\n","Loss of episode 1484 = 20.114193\n","Loss of episode 1485 = 20.096771\n","Loss of episode 1486 = 20.109154\n","Loss of episode 1487 = 20.125208\n","Loss of episode 1488 = 20.091228\n","Loss of episode 1489 = 20.109632\n","Loss of episode 1490 = 20.120808\n","Loss of episode 1491 = 20.094326\n","Loss of episode 1492 = 20.105247\n","Loss of episode 1493 = 20.110188\n","Loss of episode 1494 = 20.102446\n","Loss of episode 1495 = 20.10046\n","Loss of episode 1496 = 20.09446\n","Loss of episode 1497 = 20.100134\n","Loss of episode 1498 = 20.109463\n","Loss of episode 1499 = 20.121147\n","Loss of episode 1500 = 20.111599\n","Loss of episode 1501 = 20.127295\n","Loss of episode 1502 = 20.146587\n","Loss of episode 1503 = 20.11232\n","Loss of episode 1504 = 20.11123\n","Loss of episode 1505 = 20.148844\n","Loss of episode 1506 = 20.11348\n","Loss of episode 1507 = 20.117197\n","Loss of episode 1508 = 20.13201\n","Loss of episode 1509 = 20.107475\n","Loss of episode 1510 = 20.136173\n","Loss of episode 1511 = 20.13795\n","Loss of episode 1512 = 20.139755\n","Loss of episode 1513 = 20.12871\n","Loss of episode 1514 = 20.135155\n","Loss of episode 1515 = 20.11401\n","Loss of episode 1516 = 20.117636\n","Loss of episode 1517 = 20.09172\n","Loss of episode 1518 = 20.09724\n","Loss of episode 1519 = 20.106167\n","Loss of episode 1520 = 20.0873\n","Loss of episode 1521 = 20.073757\n","Loss of episode 1522 = 20.090225\n","Loss of episode 1523 = 20.090797\n","Loss of episode 1524 = 20.089233\n","Loss of episode 1525 = 20.112602\n","Loss of episode 1526 = 20.094635\n","Loss of episode 1527 = 20.093513\n","Loss of episode 1528 = 20.096153\n","Loss of episode 1529 = 20.108261\n","Loss of episode 1530 = 20.108694\n","Loss of episode 1531 = 20.130676\n","Loss of episode 1532 = 20.116383\n","Loss of episode 1533 = 20.132257\n","Loss of episode 1534 = 20.137386\n","Loss of episode 1535 = 20.092285\n","Loss of episode 1536 = 20.11148\n","Loss of episode 1537 = 20.098446\n","Loss of episode 1538 = 20.074636\n","Loss of episode 1539 = 20.087856\n","Loss of episode 1540 = 20.080906\n","Loss of episode 1541 = 20.066551\n","Loss of episode 1542 = 20.070652\n","Loss of episode 1543 = 20.092133\n","Loss of episode 1544 = 20.078552\n","Loss of episode 1545 = 20.084112\n","Loss of episode 1546 = 20.08882\n","Loss of episode 1547 = 20.084158\n","Loss of episode 1548 = 20.092688\n","Loss of episode 1549 = 20.08535\n","Loss of episode 1550 = 20.065697\n","Loss of episode 1551 = 20.085272\n","Loss of episode 1552 = 20.064808\n","Loss of episode 1553 = 20.060741\n","Loss of episode 1554 = 20.105703\n","Loss of episode 1555 = 20.107616\n","Loss of episode 1556 = 20.070354\n","Loss of episode 1557 = 20.087145\n","Loss of episode 1558 = 20.105274\n","Loss of episode 1559 = 20.092754\n","Loss of episode 1560 = 20.082088\n","Loss of episode 1561 = 20.109936\n","Loss of episode 1562 = 20.102825\n","Loss of episode 1563 = 20.078608\n","Loss of episode 1564 = 20.090794\n","Loss of episode 1565 = 20.10589\n","Loss of episode 1566 = 20.076988\n","Loss of episode 1567 = 20.086609\n","Loss of episode 1568 = 20.092758\n","Loss of episode 1569 = 20.089153\n","Loss of episode 1570 = 20.064795\n","Loss of episode 1571 = 20.100431\n","Loss of episode 1572 = 20.086496\n","Loss of episode 1573 = 20.073895\n","Loss of episode 1574 = 20.09236\n","Loss of episode 1575 = 20.07399\n","Loss of episode 1576 = 20.064617\n","Loss of episode 1577 = 20.082584\n","Loss of episode 1578 = 20.076319\n","Loss of episode 1579 = 20.05938\n","Loss of episode 1580 = 20.075861\n","Loss of episode 1581 = 20.07655\n","Loss of episode 1582 = 20.048923\n","Loss of episode 1583 = 20.072006\n","Loss of episode 1584 = 20.072369\n","Loss of episode 1585 = 20.056686\n","Loss of episode 1586 = 20.064617\n","Loss of episode 1587 = 20.0839\n","Loss of episode 1588 = 20.051111\n","Loss of episode 1589 = 20.052534\n","Loss of episode 1590 = 20.072037\n","Loss of episode 1591 = 20.055023\n","Loss of episode 1592 = 20.051212\n","Loss of episode 1593 = 20.085732\n","Loss of episode 1594 = 20.066013\n","Loss of episode 1595 = 20.06565\n","Loss of episode 1596 = 20.071182\n","Loss of episode 1597 = 20.069927\n","Loss of episode 1598 = 20.053734\n","Loss of episode 1599 = 20.08361\n","Loss of episode 1600 = 20.083614\n","Loss of episode 1601 = 20.06185\n","Loss of episode 1602 = 20.07585\n","Loss of episode 1603 = 20.06628\n","Loss of episode 1604 = 20.051535\n","Loss of episode 1605 = 20.06054\n","Loss of episode 1606 = 20.067045\n","Loss of episode 1607 = 20.048742\n","Loss of episode 1608 = 20.057318\n","Loss of episode 1609 = 20.059902\n","Loss of episode 1610 = 20.055641\n","Loss of episode 1611 = 20.05518\n","Loss of episode 1612 = 20.055618\n","Loss of episode 1613 = 20.043203\n","Loss of episode 1614 = 20.02816\n","Loss of episode 1615 = 20.054283\n","Loss of episode 1616 = 20.053062\n","Loss of episode 1617 = 20.057003\n","Loss of episode 1618 = 20.064983\n","Loss of episode 1619 = 20.076723\n","Loss of episode 1620 = 20.059254\n","Loss of episode 1621 = 20.07813\n","Loss of episode 1622 = 20.098686\n","Loss of episode 1623 = 20.078522\n","Loss of episode 1624 = 20.094799\n","Loss of episode 1625 = 20.134117\n","Loss of episode 1626 = 20.124104\n","Loss of episode 1627 = 20.129295\n","Loss of episode 1628 = 20.139084\n","Loss of episode 1629 = 20.114864\n","Loss of episode 1630 = 20.125074\n","Loss of episode 1631 = 20.133345\n","Loss of episode 1632 = 20.115877\n","Loss of episode 1633 = 20.110134\n","Loss of episode 1634 = 20.14198\n","Loss of episode 1635 = 20.114857\n","Loss of episode 1636 = 20.095112\n","Loss of episode 1637 = 20.10118\n","Loss of episode 1638 = 20.123661\n","Loss of episode 1639 = 20.088766\n","Loss of episode 1640 = 20.093193\n","Loss of episode 1641 = 20.079182\n","Loss of episode 1642 = 20.11903\n","Loss of episode 1643 = 20.10469\n","Loss of episode 1644 = 20.085274\n","Loss of episode 1645 = 20.10519\n","Loss of episode 1646 = 20.123505\n","Loss of episode 1647 = 20.094002\n","Loss of episode 1648 = 20.11081\n","Loss of episode 1649 = 20.14242\n","Loss of episode 1650 = 20.105652\n","Loss of episode 1651 = 20.113623\n","Loss of episode 1652 = 20.135387\n","Loss of episode 1653 = 20.102795\n","Loss of episode 1654 = 20.089811\n","Loss of episode 1655 = 20.094967\n","Loss of episode 1656 = 20.109\n","Loss of episode 1657 = 20.094341\n","Loss of episode 1658 = 20.090374\n","Loss of episode 1659 = 20.083515\n","Loss of episode 1660 = 20.080126\n","Loss of episode 1661 = 20.061398\n","Loss of episode 1662 = 20.065613\n","Loss of episode 1663 = 20.073544\n","Loss of episode 1664 = 20.067982\n","Loss of episode 1665 = 20.068314\n","Loss of episode 1666 = 20.092209\n","Loss of episode 1667 = 20.08741\n","Loss of episode 1668 = 20.080336\n","Loss of episode 1669 = 20.115612\n","Loss of episode 1670 = 20.089447\n","Loss of episode 1671 = 20.089626\n","Loss of episode 1672 = 20.12703\n","Loss of episode 1673 = 20.093075\n","Loss of episode 1674 = 20.079035\n","Loss of episode 1675 = 20.107435\n","Loss of episode 1676 = 20.081186\n","Loss of episode 1677 = 20.07552\n","Loss of episode 1678 = 20.08856\n","Loss of episode 1679 = 20.071766\n","Loss of episode 1680 = 20.057549\n","Loss of episode 1681 = 20.072426\n","Loss of episode 1682 = 20.04789\n","Loss of episode 1683 = 20.044983\n","Loss of episode 1684 = 20.054192\n","Loss of episode 1685 = 20.037077\n","Loss of episode 1686 = 20.034025\n","Loss of episode 1687 = 20.055779\n","Loss of episode 1688 = 20.026722\n","Loss of episode 1689 = 20.02779\n","Loss of episode 1690 = 20.043259\n","Loss of episode 1691 = 20.017517\n","Loss of episode 1692 = 20.034245\n","Loss of episode 1693 = 20.03925\n","Loss of episode 1694 = 20.031055\n","Loss of episode 1695 = 20.032871\n","Loss of episode 1696 = 20.048592\n","Loss of episode 1697 = 20.021645\n","Loss of episode 1698 = 20.025925\n","Loss of episode 1699 = 20.044804\n","Loss of episode 1700 = 20.028597\n","Loss of episode 1701 = 20.019987\n","Loss of episode 1702 = 20.038326\n","Loss of episode 1703 = 20.035007\n","Loss of episode 1704 = 20.01705\n","Loss of episode 1705 = 20.037077\n","Loss of episode 1706 = 20.037725\n","Loss of episode 1707 = 20.03073\n","Loss of episode 1708 = 20.045395\n","Loss of episode 1709 = 20.062193\n","Loss of episode 1710 = 20.039303\n","Loss of episode 1711 = 20.044392\n","Loss of episode 1712 = 20.060282\n","Loss of episode 1713 = 20.0397\n","Loss of episode 1714 = 20.038925\n","Loss of episode 1715 = 20.062988\n","Loss of episode 1716 = 20.045528\n","Loss of episode 1717 = 20.04815\n","Loss of episode 1718 = 20.059822\n","Loss of episode 1719 = 20.067596\n","Loss of episode 1720 = 20.050697\n","Loss of episode 1721 = 20.081837\n","Loss of episode 1722 = 20.056038\n","Loss of episode 1723 = 20.058052\n","Loss of episode 1724 = 20.094204\n","Loss of episode 1725 = 20.072361\n","Loss of episode 1726 = 20.060226\n","Loss of episode 1727 = 20.068462\n","Loss of episode 1728 = 20.068506\n","Loss of episode 1729 = 20.069523\n","Loss of episode 1730 = 20.086561\n","Loss of episode 1731 = 20.069855\n","Loss of episode 1732 = 20.070335\n","Loss of episode 1733 = 20.09179\n","Loss of episode 1734 = 20.06758\n","Loss of episode 1735 = 20.062864\n","Loss of episode 1736 = 20.080627\n","Loss of episode 1737 = 20.095924\n","Loss of episode 1738 = 20.070549\n","Loss of episode 1739 = 20.081099\n","Loss of episode 1740 = 20.059935\n","Loss of episode 1741 = 20.06438\n","Loss of episode 1742 = 20.056267\n","Loss of episode 1743 = 20.081732\n","Loss of episode 1744 = 20.099644\n","Loss of episode 1745 = 20.097425\n","Loss of episode 1746 = 20.082726\n","Loss of episode 1747 = 20.11689\n","Loss of episode 1748 = 20.11157\n","Loss of episode 1749 = 20.078691\n","Loss of episode 1750 = 20.125013\n","Loss of episode 1751 = 20.092148\n","Loss of episode 1752 = 20.057667\n","Loss of episode 1753 = 20.08027\n","Loss of episode 1754 = 20.095703\n","Loss of episode 1755 = 20.0569\n","Loss of episode 1756 = 20.092896\n","Loss of episode 1757 = 20.06788\n","Loss of episode 1758 = 20.051352\n","Loss of episode 1759 = 20.076546\n","Loss of episode 1760 = 20.055054\n","Loss of episode 1761 = 20.057621\n","Loss of episode 1762 = 20.061085\n","Loss of episode 1763 = 20.04155\n","Loss of episode 1764 = 20.05209\n","Loss of episode 1765 = 20.04814\n","Loss of episode 1766 = 20.040968\n","Loss of episode 1767 = 20.054716\n","Loss of episode 1768 = 20.046585\n","Loss of episode 1769 = 20.042961\n","Loss of episode 1770 = 20.041286\n","Loss of episode 1771 = 20.032694\n","Loss of episode 1772 = 20.0332\n","Loss of episode 1773 = 20.050022\n","Loss of episode 1774 = 20.05853\n","Loss of episode 1775 = 20.04754\n","Loss of episode 1776 = 20.053175\n","Loss of episode 1777 = 20.040533\n","Loss of episode 1778 = 20.042013\n","Loss of episode 1779 = 20.057423\n","Loss of episode 1780 = 20.025642\n","Loss of episode 1781 = 20.056705\n","Loss of episode 1782 = 20.058064\n","Loss of episode 1783 = 20.039612\n","Loss of episode 1784 = 20.034975\n","Loss of episode 1785 = 20.049149\n","Loss of episode 1786 = 20.027563\n","Loss of episode 1787 = 20.026676\n","Loss of episode 1788 = 20.037733\n","Loss of episode 1789 = 20.046913\n","Loss of episode 1790 = 20.033146\n","Loss of episode 1791 = 20.038368\n","Loss of episode 1792 = 20.039625\n","Loss of episode 1793 = 20.044918\n","Loss of episode 1794 = 20.031218\n","Loss of episode 1795 = 20.039785\n","Loss of episode 1796 = 20.045874\n","Loss of episode 1797 = 20.024826\n","Loss of episode 1798 = 20.034298\n","Loss of episode 1799 = 20.038483\n","Loss of episode 1800 = 20.054115\n","Loss of episode 1801 = 20.040794\n","Loss of episode 1802 = 20.033783\n","Loss of episode 1803 = 20.066166\n","Loss of episode 1804 = 20.04507\n","Loss of episode 1805 = 20.036617\n","Loss of episode 1806 = 20.077522\n","Loss of episode 1807 = 20.055323\n","Loss of episode 1808 = 20.054852\n","Loss of episode 1809 = 20.079617\n","Loss of episode 1810 = 20.074564\n","Loss of episode 1811 = 20.064377\n","Loss of episode 1812 = 20.073019\n","Loss of episode 1813 = 20.066038\n","Loss of episode 1814 = 20.069462\n","Loss of episode 1815 = 20.061707\n","Loss of episode 1816 = 20.067759\n","Loss of episode 1817 = 20.071438\n","Loss of episode 1818 = 20.089159\n","Loss of episode 1819 = 20.054682\n","Loss of episode 1820 = 20.088604\n","Loss of episode 1821 = 20.083963\n","Loss of episode 1822 = 20.059093\n","Loss of episode 1823 = 20.100231\n","Loss of episode 1824 = 20.09618\n","Loss of episode 1825 = 20.05096\n","Loss of episode 1826 = 20.087431\n","Loss of episode 1827 = 20.076015\n","Loss of episode 1828 = 20.051994\n","Loss of episode 1829 = 20.052631\n","Loss of episode 1830 = 20.051008\n","Loss of episode 1831 = 20.023712\n","Loss of episode 1832 = 20.05489\n","Loss of episode 1833 = 20.03117\n","Loss of episode 1834 = 20.017052\n","Loss of episode 1835 = 20.045624\n","Loss of episode 1836 = 20.04282\n","Loss of episode 1837 = 20.031889\n","Loss of episode 1838 = 20.067593\n","Loss of episode 1839 = 20.023937\n","Loss of episode 1840 = 20.024546\n","Loss of episode 1841 = 20.055109\n","Loss of episode 1842 = 20.038914\n","Loss of episode 1843 = 20.050123\n","Loss of episode 1844 = 20.063637\n","Loss of episode 1845 = 20.05598\n","Loss of episode 1846 = 20.057215\n","Loss of episode 1847 = 20.04393\n","Loss of episode 1848 = 20.036488\n","Loss of episode 1849 = 20.040226\n","Loss of episode 1850 = 20.022247\n","Loss of episode 1851 = 20.02573\n","Loss of episode 1852 = 20.046255\n","Loss of episode 1853 = 20.028435\n","Loss of episode 1854 = 20.023369\n","Loss of episode 1855 = 20.06794\n","Loss of episode 1856 = 20.018618\n","Loss of episode 1857 = 20.04934\n","Loss of episode 1858 = 20.02865\n","Loss of episode 1859 = 20.026108\n","Loss of episode 1860 = 20.041168\n","Loss of episode 1861 = 20.02893\n","Loss of episode 1862 = 20.025211\n","Loss of episode 1863 = 20.021313\n","Loss of episode 1864 = 20.005085\n","Loss of episode 1865 = 20.029154\n","Loss of episode 1866 = 20.027828\n","Loss of episode 1867 = 20.011036\n","Loss of episode 1868 = 20.022305\n","Loss of episode 1869 = 20.031605\n","Loss of episode 1870 = 20.012205\n","Loss of episode 1871 = 20.031246\n","Loss of episode 1872 = 20.021479\n","Loss of episode 1873 = 20.005577\n","Loss of episode 1874 = 20.017225\n","Loss of episode 1875 = 20.020477\n","Loss of episode 1876 = 20.009037\n","Loss of episode 1877 = 20.022127\n","Loss of episode 1878 = 20.02947\n","Loss of episode 1879 = 20.032347\n","Loss of episode 1880 = 20.033222\n","Loss of episode 1881 = 20.028248\n","Loss of episode 1882 = 20.011078\n","Loss of episode 1883 = 20.037262\n","Loss of episode 1884 = 20.02526\n","Loss of episode 1885 = 20.00834\n","Loss of episode 1886 = 20.036015\n","Loss of episode 1887 = 20.016226\n","Loss of episode 1888 = 20.016499\n","Loss of episode 1889 = 20.022036\n","Loss of episode 1890 = 20.03425\n","Loss of episode 1891 = 20.019444\n","Loss of episode 1892 = 20.032534\n","Loss of episode 1893 = 20.04219\n","Loss of episode 1894 = 20.03757\n","Loss of episode 1895 = 20.033209\n","Loss of episode 1896 = 20.02458\n","Loss of episode 1897 = 20.01993\n","Loss of episode 1898 = 20.050179\n","Loss of episode 1899 = 20.030287\n","Loss of episode 1900 = 20.055824\n","Loss of episode 1901 = 20.065277\n","Loss of episode 1902 = 20.030197\n","Loss of episode 1903 = 20.040365\n","Loss of episode 1904 = 20.043\n","Loss of episode 1905 = 20.01483\n","Loss of episode 1906 = 20.041227\n","Loss of episode 1907 = 20.037218\n","Loss of episode 1908 = 20.023403\n","Loss of episode 1909 = 20.039083\n","Loss of episode 1910 = 20.025093\n","Loss of episode 1911 = 20.032475\n","Loss of episode 1912 = 20.040289\n","Loss of episode 1913 = 20.018988\n","Loss of episode 1914 = 20.041859\n","Loss of episode 1915 = 20.032408\n","Loss of episode 1916 = 20.01853\n","Loss of episode 1917 = 20.045753\n","Loss of episode 1918 = 20.056736\n","Loss of episode 1919 = 20.022484\n","Loss of episode 1920 = 20.04577\n","Loss of episode 1921 = 20.052605\n","Loss of episode 1922 = 20.045586\n","Loss of episode 1923 = 20.045284\n","Loss of episode 1924 = 20.044247\n","Loss of episode 1925 = 20.038292\n","Loss of episode 1926 = 20.034283\n","Loss of episode 1927 = 20.019253\n","Loss of episode 1928 = 20.05006\n","Loss of episode 1929 = 20.030037\n","Loss of episode 1930 = 20.0095\n","Loss of episode 1931 = 20.02978\n","Loss of episode 1932 = 20.035099\n","Loss of episode 1933 = 20.003918\n","Loss of episode 1934 = 20.036165\n","Loss of episode 1935 = 20.023613\n","Loss of episode 1936 = 20.022846\n","Loss of episode 1937 = 20.029388\n","Loss of episode 1938 = 20.035835\n","Loss of episode 1939 = 20.004587\n","Loss of episode 1940 = 20.016338\n","Loss of episode 1941 = 20.020199\n","Loss of episode 1942 = 20.006613\n","Loss of episode 1943 = 20.002987\n","Loss of episode 1944 = 20.018705\n","Loss of episode 1945 = 19.996443\n","Loss of episode 1946 = 20.01555\n","Loss of episode 1947 = 20.000973\n","Loss of episode 1948 = 19.999388\n","Loss of episode 1949 = 20.00723\n","Loss of episode 1950 = 20.02063\n","Loss of episode 1951 = 20.015182\n","Loss of episode 1952 = 20.020733\n","Loss of episode 1953 = 20.028698\n","Loss of episode 1954 = 20.033594\n","Loss of episode 1955 = 20.047293\n","Loss of episode 1956 = 20.029013\n","Loss of episode 1957 = 20.032837\n","Loss of episode 1958 = 20.05128\n","Loss of episode 1959 = 20.036285\n","Loss of episode 1960 = 20.052174\n","Loss of episode 1961 = 20.069447\n","Loss of episode 1962 = 20.012777\n","Loss of episode 1963 = 20.035492\n","Loss of episode 1964 = 20.037415\n","Loss of episode 1965 = 20.012512\n","Loss of episode 1966 = 20.027887\n","Loss of episode 1967 = 20.026953\n","Loss of episode 1968 = 19.998081\n","Loss of episode 1969 = 20.016659\n","Loss of episode 1970 = 20.004486\n","Loss of episode 1971 = 20.00899\n","Loss of episode 1972 = 20.008224\n","Loss of episode 1973 = 20.004873\n","Loss of episode 1974 = 20.018991\n","Loss of episode 1975 = 20.014706\n","Loss of episode 1976 = 20.003733\n","Loss of episode 1977 = 20.010056\n","Loss of episode 1978 = 20.005322\n","Loss of episode 1979 = 19.995592\n","Loss of episode 1980 = 19.999767\n","Loss of episode 1981 = 20.004944\n","Loss of episode 1982 = 19.988022\n","Loss of episode 1983 = 20.005295\n","Loss of episode 1984 = 20.006891\n","Loss of episode 1985 = 19.998333\n","Loss of episode 1986 = 20.006853\n","Loss of episode 1987 = 20.001997\n","Loss of episode 1988 = 20.00262\n","Loss of episode 1989 = 20.009214\n","Loss of episode 1990 = 19.996923\n","Loss of episode 1991 = 20.003994\n","Loss of episode 1992 = 20.002956\n","Loss of episode 1993 = 19.996107\n","Loss of episode 1994 = 20.000599\n","Loss of episode 1995 = 20.01897\n","Loss of episode 1996 = 20.009941\n","Loss of episode 1997 = 20.000296\n","Loss of episode 1998 = 20.015652\n","Loss of episode 1999 = 20.012064\n","Loss of episode 2000 = 19.99681\n","Loss of episode 2001 = 20.018631\n","Loss of episode 2002 = 20.018362\n","Loss of episode 2003 = 20.006815\n","Loss of episode 2004 = 20.029055\n","Loss of episode 2005 = 20.0167\n","Loss of episode 2006 = 20.016056\n","Loss of episode 2007 = 20.018137\n","Loss of episode 2008 = 20.0176\n","Loss of episode 2009 = 20.003437\n","Loss of episode 2010 = 20.007652\n","Loss of episode 2011 = 20.019703\n","Loss of episode 2012 = 20.006756\n","Loss of episode 2013 = 20.005335\n","Loss of episode 2014 = 20.015661\n","Loss of episode 2015 = 20.022488\n","Loss of episode 2016 = 20.031708\n","Loss of episode 2017 = 20.026585\n","Loss of episode 2018 = 20.003416\n","Loss of episode 2019 = 20.018785\n","Loss of episode 2020 = 20.018028\n","Loss of episode 2021 = 20.005276\n","Loss of episode 2022 = 20.034826\n","Loss of episode 2023 = 20.022087\n","Loss of episode 2024 = 20.025646\n","Loss of episode 2025 = 20.034424\n","Loss of episode 2026 = 20.012594\n","Loss of episode 2027 = 20.01191\n","Loss of episode 2028 = 20.033356\n","Loss of episode 2029 = 20.007015\n","Loss of episode 2030 = 20.013657\n","Loss of episode 2031 = 20.034492\n","Loss of episode 2032 = 20.0227\n","Loss of episode 2033 = 20.012043\n","Loss of episode 2034 = 20.024237\n","Loss of episode 2035 = 20.017735\n","Loss of episode 2036 = 20.009237\n","Loss of episode 2037 = 20.030338\n","Loss of episode 2038 = 20.007025\n","Loss of episode 2039 = 20.0129\n","Loss of episode 2040 = 20.017752\n","Loss of episode 2041 = 20.013664\n","Loss of episode 2042 = 20.015793\n","Loss of episode 2043 = 20.032194\n","Loss of episode 2044 = 20.020824\n","Loss of episode 2045 = 20.021492\n","Loss of episode 2046 = 20.026375\n","Loss of episode 2047 = 20.01744\n","Loss of episode 2048 = 20.011114\n","Loss of episode 2049 = 20.022194\n","Loss of episode 2050 = 19.998323\n","Loss of episode 2051 = 20.00077\n","Loss of episode 2052 = 20.012045\n","Loss of episode 2053 = 19.993103\n","Loss of episode 2054 = 20.014044\n","Loss of episode 2055 = 20.01382\n","Loss of episode 2056 = 19.997545\n","Loss of episode 2057 = 20.005299\n","Loss of episode 2058 = 19.999588\n","Loss of episode 2059 = 19.985306\n","Loss of episode 2060 = 19.993078\n","Loss of episode 2061 = 19.978844\n","Loss of episode 2062 = 19.979752\n","Loss of episode 2063 = 19.990013\n","Loss of episode 2064 = 19.964924\n","Loss of episode 2065 = 19.96905\n","Loss of episode 2066 = 19.990795\n","Loss of episode 2067 = 19.973158\n","Loss of episode 2068 = 19.970839\n","Loss of episode 2069 = 19.980417\n","Loss of episode 2070 = 19.962433\n","Loss of episode 2071 = 19.975338\n","Loss of episode 2072 = 19.974976\n","Loss of episode 2073 = 19.966537\n","Loss of episode 2074 = 19.974533\n","Loss of episode 2075 = 19.975151\n","Loss of episode 2076 = 19.964827\n","Loss of episode 2077 = 19.976841\n","Loss of episode 2078 = 19.995337\n","Loss of episode 2079 = 19.983318\n","Loss of episode 2080 = 19.985731\n","Loss of episode 2081 = 20.003897\n","Loss of episode 2082 = 19.993263\n","Loss of episode 2083 = 20.012318\n","Loss of episode 2084 = 20.00557\n","Loss of episode 2085 = 19.99918\n","Loss of episode 2086 = 19.981562\n","Loss of episode 2087 = 19.991432\n","Loss of episode 2088 = 19.982338\n","Loss of episode 2089 = 19.997208\n","Loss of episode 2090 = 20.004648\n","Loss of episode 2091 = 19.984526\n","Loss of episode 2092 = 19.991833\n","Loss of episode 2093 = 20.002134\n","Loss of episode 2094 = 20.001064\n","Loss of episode 2095 = 19.995617\n","Loss of episode 2096 = 20.029554\n","Loss of episode 2097 = 19.998096\n","Loss of episode 2098 = 20.012167\n","Loss of episode 2099 = 20.017103\n","Loss of episode 2100 = 20.016613\n","Loss of episode 2101 = 20.02367\n","Loss of episode 2102 = 20.025599\n","Loss of episode 2103 = 20.006903\n","Loss of episode 2104 = 20.036018\n","Loss of episode 2105 = 20.023209\n","Loss of episode 2106 = 20.005745\n","Loss of episode 2107 = 20.016136\n","Loss of episode 2108 = 20.002056\n","Loss of episode 2109 = 20.015976\n","Loss of episode 2110 = 20.001644\n","Loss of episode 2111 = 20.01916\n","Loss of episode 2112 = 20.038082\n","Loss of episode 2113 = 20.025185\n","Loss of episode 2114 = 20.031158\n","Loss of episode 2115 = 20.044918\n","Loss of episode 2116 = 20.038082\n","Loss of episode 2117 = 20.019941\n","Loss of episode 2118 = 20.014004\n","Loss of episode 2119 = 20.028238\n","Loss of episode 2120 = 20.001915\n","Loss of episode 2121 = 19.990517\n","Loss of episode 2122 = 20.01566\n","Loss of episode 2123 = 20.00221\n","Loss of episode 2124 = 19.997633\n","Loss of episode 2125 = 20.004185\n","Loss of episode 2126 = 19.996391\n","Loss of episode 2127 = 19.990948\n","Loss of episode 2128 = 19.990906\n","Loss of episode 2129 = 20.012655\n","Loss of episode 2130 = 19.994797\n","Loss of episode 2131 = 19.981602\n","Loss of episode 2132 = 19.993732\n","Loss of episode 2133 = 20.003763\n","Loss of episode 2134 = 19.989264\n","Loss of episode 2135 = 19.989887\n","Loss of episode 2136 = 19.99709\n","Loss of episode 2137 = 20.004086\n","Loss of episode 2138 = 19.998278\n","Loss of episode 2139 = 20.027458\n","Loss of episode 2140 = 20.006641\n","Loss of episode 2141 = 20.014023\n","Loss of episode 2142 = 20.04646\n","Loss of episode 2143 = 20.00127\n","Loss of episode 2144 = 20.017513\n","Loss of episode 2145 = 20.036312\n","Loss of episode 2146 = 20.01195\n","Loss of episode 2147 = 20.008541\n","Loss of episode 2148 = 20.030895\n","Loss of episode 2149 = 20.001163\n","Loss of episode 2150 = 19.999462\n","Loss of episode 2151 = 20.011892\n","Loss of episode 2152 = 19.98947\n","Loss of episode 2153 = 19.986557\n","Loss of episode 2154 = 19.995079\n","Loss of episode 2155 = 19.977673\n","Loss of episode 2156 = 19.983555\n","Loss of episode 2157 = 19.99339\n","Loss of episode 2158 = 19.988354\n","Loss of episode 2159 = 19.998499\n","Loss of episode 2160 = 19.998505\n","Loss of episode 2161 = 19.97491\n","Loss of episode 2162 = 20.002962\n","Loss of episode 2163 = 20.004261\n","Loss of episode 2164 = 19.993431\n","Loss of episode 2165 = 20.017593\n","Loss of episode 2166 = 20.000671\n","Loss of episode 2167 = 19.992996\n","Loss of episode 2168 = 19.990242\n","Loss of episode 2169 = 19.970955\n","Loss of episode 2170 = 19.98454\n","Loss of episode 2171 = 19.984348\n","Loss of episode 2172 = 19.971584\n","Loss of episode 2173 = 19.974575\n","Loss of episode 2174 = 19.977175\n","Loss of episode 2175 = 19.958586\n","Loss of episode 2176 = 19.973188\n","Loss of episode 2177 = 19.966122\n","Loss of episode 2178 = 19.960632\n","Loss of episode 2179 = 19.979187\n","Loss of episode 2180 = 19.967281\n","Loss of episode 2181 = 19.970907\n","Loss of episode 2182 = 19.990566\n","Loss of episode 2183 = 19.97666\n","Loss of episode 2184 = 19.964512\n","Loss of episode 2185 = 19.991993\n","Loss of episode 2186 = 19.974428\n","Loss of episode 2187 = 19.979591\n","Loss of episode 2188 = 19.9864\n","Loss of episode 2189 = 19.960724\n","Loss of episode 2190 = 19.988764\n","Loss of episode 2191 = 19.987309\n","Loss of episode 2192 = 19.970758\n","Loss of episode 2193 = 19.975368\n","Loss of episode 2194 = 19.987694\n","Loss of episode 2195 = 19.97447\n","Loss of episode 2196 = 19.998505\n","Loss of episode 2197 = 19.992744\n","Loss of episode 2198 = 19.996819\n","Loss of episode 2199 = 20.013191\n","Loss of episode 2200 = 19.984318\n","Loss of episode 2201 = 20.001196\n","Loss of episode 2202 = 20.029621\n","Loss of episode 2203 = 20.003647\n","Loss of episode 2204 = 20.010723\n","Loss of episode 2205 = 20.027569\n","Loss of episode 2206 = 19.9973\n","Loss of episode 2207 = 19.995993\n","Loss of episode 2208 = 20.018616\n","Loss of episode 2209 = 20.009886\n","Loss of episode 2210 = 20.005392\n","Loss of episode 2211 = 20.013313\n","Loss of episode 2212 = 20.022291\n","Loss of episode 2213 = 20.018183\n","Loss of episode 2214 = 20.016903\n","Loss of episode 2215 = 20.018389\n","Loss of episode 2216 = 20.043732\n","Loss of episode 2217 = 20.022667\n","Loss of episode 2218 = 20.061932\n","Loss of episode 2219 = 20.045727\n","Loss of episode 2220 = 20.021236\n","Loss of episode 2221 = 20.024822\n","Loss of episode 2222 = 20.01926\n","Loss of episode 2223 = 20.008152\n","Loss of episode 2224 = 20.01157\n","Loss of episode 2225 = 19.9884\n","Loss of episode 2226 = 19.988564\n","Loss of episode 2227 = 19.996952\n","Loss of episode 2228 = 19.977287\n","Loss of episode 2229 = 19.969933\n","Loss of episode 2230 = 20.005152\n","Loss of episode 2231 = 19.968784\n","Loss of episode 2232 = 19.982029\n","Loss of episode 2233 = 19.974615\n","Loss of episode 2234 = 19.969498\n","Loss of episode 2235 = 19.966478\n","Loss of episode 2236 = 19.960972\n","Loss of episode 2237 = 19.945461\n","Loss of episode 2238 = 19.949402\n","Loss of episode 2239 = 19.93412\n","Loss of episode 2240 = 19.951483\n","Loss of episode 2241 = 19.944\n","Loss of episode 2242 = 19.955383\n","Loss of episode 2243 = 19.95771\n","Loss of episode 2244 = 19.956463\n","Loss of episode 2245 = 19.948036\n","Loss of episode 2246 = 19.976273\n","Loss of episode 2247 = 19.97055\n","Loss of episode 2248 = 19.967945\n","Loss of episode 2249 = 19.985378\n","Loss of episode 2250 = 19.977577\n","Loss of episode 2251 = 19.973478\n","Loss of episode 2252 = 20.022589\n","Loss of episode 2253 = 19.98808\n","Loss of episode 2254 = 19.993862\n","Loss of episode 2255 = 20.016632\n","Loss of episode 2256 = 19.994595\n","Loss of episode 2257 = 19.99653\n","Loss of episode 2258 = 20.00996\n","Loss of episode 2259 = 19.987844\n","Loss of episode 2260 = 20.0138\n","Loss of episode 2261 = 19.983833\n","Loss of episode 2262 = 19.97884\n","Loss of episode 2263 = 19.98948\n","Loss of episode 2264 = 19.976614\n","Loss of episode 2265 = 19.989532\n","Loss of episode 2266 = 19.988592\n","Loss of episode 2267 = 19.978012\n","Loss of episode 2268 = 19.991516\n","Loss of episode 2269 = 19.97244\n","Loss of episode 2270 = 19.973896\n","Loss of episode 2271 = 19.976522\n","Loss of episode 2272 = 19.962986\n","Loss of episode 2273 = 19.951248\n","Loss of episode 2274 = 19.982895\n","Loss of episode 2275 = 19.953663\n","Loss of episode 2276 = 19.956818\n","Loss of episode 2277 = 19.9762\n","Loss of episode 2278 = 19.95367\n","Loss of episode 2279 = 19.970022\n","Loss of episode 2280 = 19.9738\n","Loss of episode 2281 = 19.974373\n","Loss of episode 2282 = 19.98766\n","Loss of episode 2283 = 19.981224\n","Loss of episode 2284 = 19.992805\n","Loss of episode 2285 = 19.988188\n","Loss of episode 2286 = 19.986242\n","Loss of episode 2287 = 20.002846\n","Loss of episode 2288 = 19.99102\n","Loss of episode 2289 = 19.984827\n","Loss of episode 2290 = 20.014086\n","Loss of episode 2291 = 19.98658\n","Loss of episode 2292 = 19.995792\n","Loss of episode 2293 = 19.992382\n","Loss of episode 2294 = 19.965944\n","Loss of episode 2295 = 19.967665\n","Loss of episode 2296 = 19.97938\n","Loss of episode 2297 = 19.9748\n","Loss of episode 2298 = 19.989521\n","Loss of episode 2299 = 19.972652\n","Loss of episode 2300 = 19.983286\n","Loss of episode 2301 = 19.975433\n","Loss of episode 2302 = 19.993645\n","Loss of episode 2303 = 19.98534\n","Loss of episode 2304 = 19.980263\n","Loss of episode 2305 = 19.990026\n","Loss of episode 2306 = 19.991833\n","Loss of episode 2307 = 19.980158\n","Loss of episode 2308 = 19.989243\n","Loss of episode 2309 = 19.986431\n","Loss of episode 2310 = 19.976654\n","Loss of episode 2311 = 19.997683\n","Loss of episode 2312 = 19.989908\n","Loss of episode 2313 = 19.964912\n","Loss of episode 2314 = 19.991413\n","Loss of episode 2315 = 19.966425\n","Loss of episode 2316 = 19.965559\n","Loss of episode 2317 = 19.984272\n","Loss of episode 2318 = 19.963898\n","Loss of episode 2319 = 19.987041\n","Loss of episode 2320 = 19.969397\n","Loss of episode 2321 = 19.953505\n","Loss of episode 2322 = 19.963478\n","Loss of episode 2323 = 19.953632\n","Loss of episode 2324 = 19.944172\n","Loss of episode 2325 = 19.935707\n","Loss of episode 2326 = 19.936462\n","Loss of episode 2327 = 19.939869\n","Loss of episode 2328 = 19.926025\n","Loss of episode 2329 = 19.951117\n","Loss of episode 2330 = 19.941868\n","Loss of episode 2331 = 19.940481\n","Loss of episode 2332 = 19.957191\n","Loss of episode 2333 = 19.94123\n","Loss of episode 2334 = 19.939074\n","Loss of episode 2335 = 19.948757\n","Loss of episode 2336 = 19.951725\n","Loss of episode 2337 = 19.94347\n","Loss of episode 2338 = 19.932487\n","Loss of episode 2339 = 19.956514\n","Loss of episode 2340 = 19.944227\n","Loss of episode 2341 = 19.955063\n","Loss of episode 2342 = 19.966385\n","Loss of episode 2343 = 19.974552\n","Loss of episode 2344 = 19.965858\n","Loss of episode 2345 = 20.008366\n","Loss of episode 2346 = 19.985075\n","Loss of episode 2347 = 20.001572\n","Loss of episode 2348 = 19.99073\n","Loss of episode 2349 = 20.001972\n","Loss of episode 2350 = 19.98957\n","Loss of episode 2351 = 19.99004\n","Loss of episode 2352 = 20.015488\n","Loss of episode 2353 = 20.003384\n","Loss of episode 2354 = 19.995949\n","Loss of episode 2355 = 20.010042\n","Loss of episode 2356 = 19.99864\n","Loss of episode 2357 = 19.990013\n","Loss of episode 2358 = 19.998718\n","Loss of episode 2359 = 19.981422\n","Loss of episode 2360 = 19.989319\n","Loss of episode 2361 = 19.985985\n","Loss of episode 2362 = 19.967987\n","Loss of episode 2363 = 19.972786\n","Loss of episode 2364 = 19.98625\n","Loss of episode 2365 = 19.968735\n","Loss of episode 2366 = 19.985626\n","Loss of episode 2367 = 19.97319\n","Loss of episode 2368 = 19.972431\n","Loss of episode 2369 = 19.985558\n","Loss of episode 2370 = 19.974663\n","Loss of episode 2371 = 19.959312\n","Loss of episode 2372 = 19.953203\n","Loss of episode 2373 = 19.941132\n","Loss of episode 2374 = 19.950027\n","Loss of episode 2375 = 19.958168\n","Loss of episode 2376 = 19.930727\n","Loss of episode 2377 = 19.950718\n","Loss of episode 2378 = 19.948814\n","Loss of episode 2379 = 19.930359\n","Loss of episode 2380 = 19.956581\n","Loss of episode 2381 = 19.953362\n","Loss of episode 2382 = 19.954762\n","Loss of episode 2383 = 19.981472\n","Loss of episode 2384 = 19.954975\n","Loss of episode 2385 = 19.970192\n","Loss of episode 2386 = 19.98238\n","Loss of episode 2387 = 19.943224\n","Loss of episode 2388 = 19.993385\n","Loss of episode 2389 = 19.968796\n","Loss of episode 2390 = 19.951431\n","Loss of episode 2391 = 19.973137\n","Loss of episode 2392 = 19.950777\n","Loss of episode 2393 = 19.962145\n","Loss of episode 2394 = 19.95528\n","Loss of episode 2395 = 19.947495\n","Loss of episode 2396 = 19.941435\n","Loss of episode 2397 = 19.944613\n","Loss of episode 2398 = 19.942451\n","Loss of episode 2399 = 19.943344\n","Loss of episode 2400 = 19.940617\n","Loss of episode 2401 = 19.945862\n","Loss of episode 2402 = 19.946022\n","Loss of episode 2403 = 19.932713\n","Loss of episode 2404 = 19.928679\n","Loss of episode 2405 = 19.922129\n","Loss of episode 2406 = 19.920948\n","Loss of episode 2407 = 19.915314\n","Loss of episode 2408 = 19.925783\n","Loss of episode 2409 = 19.914684\n","Loss of episode 2410 = 19.91724\n","Loss of episode 2411 = 19.934616\n","Loss of episode 2412 = 19.91838\n","Loss of episode 2413 = 19.921059\n","Loss of episode 2414 = 19.930233\n","Loss of episode 2415 = 19.931019\n","Loss of episode 2416 = 19.937683\n","Loss of episode 2417 = 19.94384\n","Loss of episode 2418 = 19.923271\n","Loss of episode 2419 = 19.940115\n","Loss of episode 2420 = 19.942265\n","Loss of episode 2421 = 19.946497\n","Loss of episode 2422 = 19.94724\n","Loss of episode 2423 = 19.931229\n","Loss of episode 2424 = 19.929642\n","Loss of episode 2425 = 19.934072\n","Loss of episode 2426 = 19.937277\n","Loss of episode 2427 = 19.923729\n","Loss of episode 2428 = 19.94401\n","Loss of episode 2429 = 19.953163\n","Loss of episode 2430 = 19.94291\n","Loss of episode 2431 = 19.970278\n","Loss of episode 2432 = 19.962997\n","Loss of episode 2433 = 19.971245\n","Loss of episode 2434 = 19.973898\n","Loss of episode 2435 = 19.972271\n","Loss of episode 2436 = 19.957256\n","Loss of episode 2437 = 19.96732\n","Loss of episode 2438 = 19.960281\n","Loss of episode 2439 = 19.949045\n","Loss of episode 2440 = 19.95507\n","Loss of episode 2441 = 19.958158\n","Loss of episode 2442 = 19.944826\n","Loss of episode 2443 = 19.96088\n","Loss of episode 2444 = 19.964136\n","Loss of episode 2445 = 19.958506\n","Loss of episode 2446 = 19.972038\n","Loss of episode 2447 = 19.956741\n","Loss of episode 2448 = 19.960838\n","Loss of episode 2449 = 19.981197\n","Loss of episode 2450 = 19.96199\n","Loss of episode 2451 = 19.976162\n","Loss of episode 2452 = 19.991669\n","Loss of episode 2453 = 19.977686\n","Loss of episode 2454 = 20.01067\n","Loss of episode 2455 = 20.007364\n","Loss of episode 2456 = 19.97658\n","Loss of episode 2457 = 19.97563\n","Loss of episode 2458 = 20.000866\n","Loss of episode 2459 = 19.977013\n","Loss of episode 2460 = 19.978058\n","Loss of episode 2461 = 19.985943\n","Loss of episode 2462 = 19.9881\n","Loss of episode 2463 = 19.972103\n","Loss of episode 2464 = 19.98523\n","Loss of episode 2465 = 19.981083\n","Loss of episode 2466 = 19.97254\n","Loss of episode 2467 = 19.980541\n","Loss of episode 2468 = 19.987858\n","Loss of episode 2469 = 19.973097\n","Loss of episode 2470 = 19.982435\n","Loss of episode 2471 = 19.998663\n","Loss of episode 2472 = 19.971518\n","Loss of episode 2473 = 19.980404\n","Loss of episode 2474 = 19.984211\n","Loss of episode 2475 = 19.948923\n","Loss of episode 2476 = 19.972933\n","Loss of episode 2477 = 19.965986\n","Loss of episode 2478 = 19.955915\n","Loss of episode 2479 = 19.971533\n","Loss of episode 2480 = 19.969467\n","Loss of episode 2481 = 19.953463\n","Loss of episode 2482 = 19.953026\n","Loss of episode 2483 = 19.949379\n","Loss of episode 2484 = 19.943554\n","Loss of episode 2485 = 19.949928\n","Loss of episode 2486 = 19.944817\n","Loss of episode 2487 = 19.944777\n","Loss of episode 2488 = 19.949814\n","Loss of episode 2489 = 19.943125\n","Loss of episode 2490 = 19.96675\n","Loss of episode 2491 = 19.948872\n","Loss of episode 2492 = 19.94624\n","Loss of episode 2493 = 19.974174\n","Loss of episode 2494 = 19.96218\n","Loss of episode 2495 = 19.958738\n","Loss of episode 2496 = 19.971447\n","Loss of episode 2497 = 19.953295\n","Loss of episode 2498 = 19.973116\n","Loss of episode 2499 = 19.966724\n","Loss of episode 2500 = 19.963863\n","Loss of episode 2501 = 19.977875\n","Loss of episode 2502 = 19.9586\n","Loss of episode 2503 = 19.958508\n","Loss of episode 2504 = 19.95163\n","Loss of episode 2505 = 19.94392\n","Loss of episode 2506 = 19.957119\n","Loss of episode 2507 = 19.959606\n","Loss of episode 2508 = 19.959717\n","Loss of episode 2509 = 19.965408\n","Loss of episode 2510 = 19.952183\n","Loss of episode 2511 = 19.956022\n","Loss of episode 2512 = 19.95641\n","Loss of episode 2513 = 19.944813\n","Loss of episode 2514 = 19.9541\n","Loss of episode 2515 = 19.954844\n","Loss of episode 2516 = 19.931267\n","Loss of episode 2517 = 19.937878\n","Loss of episode 2518 = 19.940289\n","Loss of episode 2519 = 19.911266\n","Loss of episode 2520 = 19.927694\n","Loss of episode 2521 = 19.914589\n","Loss of episode 2522 = 19.922123\n","Loss of episode 2523 = 19.934402\n","Loss of episode 2524 = 19.919275\n","Loss of episode 2525 = 19.9262\n","Loss of episode 2526 = 19.93705\n","Loss of episode 2527 = 19.92547\n","Loss of episode 2528 = 19.9356\n","Loss of episode 2529 = 19.925835\n","Loss of episode 2530 = 19.930035\n","Loss of episode 2531 = 19.934464\n","Loss of episode 2532 = 19.940845\n","Loss of episode 2533 = 19.93205\n","Loss of episode 2534 = 19.931221\n","Loss of episode 2535 = 19.941374\n","Loss of episode 2536 = 19.941183\n","Loss of episode 2537 = 19.952026\n","Loss of episode 2538 = 19.945665\n","Loss of episode 2539 = 19.95301\n","Loss of episode 2540 = 19.949974\n","Loss of episode 2541 = 19.966879\n","Loss of episode 2542 = 19.967243\n","Loss of episode 2543 = 19.952784\n","Loss of episode 2544 = 19.959442\n","Loss of episode 2545 = 19.96458\n","Loss of episode 2546 = 19.949747\n","Loss of episode 2547 = 19.969236\n","Loss of episode 2548 = 19.959728\n","Loss of episode 2549 = 19.942112\n","Loss of episode 2550 = 19.947094\n","Loss of episode 2551 = 19.965807\n","Loss of episode 2552 = 19.959862\n","Loss of episode 2553 = 19.96165\n","Loss of episode 2554 = 19.96074\n","Loss of episode 2555 = 19.947725\n","Loss of episode 2556 = 19.953896\n","Loss of episode 2557 = 19.959328\n","Loss of episode 2558 = 19.956667\n","Loss of episode 2559 = 19.97321\n","Loss of episode 2560 = 19.946526\n","Loss of episode 2561 = 19.9655\n","Loss of episode 2562 = 19.961313\n","Loss of episode 2563 = 19.954826\n","Loss of episode 2564 = 19.977169\n","Loss of episode 2565 = 19.966269\n","Loss of episode 2566 = 19.955862\n","Loss of episode 2567 = 19.97245\n","Loss of episode 2568 = 19.959023\n","Loss of episode 2569 = 19.951567\n","Loss of episode 2570 = 19.94711\n","Loss of episode 2571 = 19.93042\n","Loss of episode 2572 = 19.950356\n","Loss of episode 2573 = 19.95405\n","Loss of episode 2574 = 19.930878\n","Loss of episode 2575 = 19.939657\n","Loss of episode 2576 = 19.926445\n","Loss of episode 2577 = 19.932743\n","Loss of episode 2578 = 19.945892\n","Loss of episode 2579 = 19.931973\n","Loss of episode 2580 = 19.928764\n","Loss of episode 2581 = 19.94792\n","Loss of episode 2582 = 19.941257\n","Loss of episode 2583 = 19.957209\n","Loss of episode 2584 = 19.949368\n","Loss of episode 2585 = 19.96706\n","Loss of episode 2586 = 19.997303\n","Loss of episode 2587 = 19.970734\n","Loss of episode 2588 = 19.974697\n","Loss of episode 2589 = 19.985868\n","Loss of episode 2590 = 19.954414\n","Loss of episode 2591 = 19.973648\n","Loss of episode 2592 = 19.977226\n","Loss of episode 2593 = 19.96\n","Loss of episode 2594 = 19.970772\n","Loss of episode 2595 = 19.959583\n","Loss of episode 2596 = 19.950912\n","Loss of episode 2597 = 19.947668\n","Loss of episode 2598 = 19.927946\n","Loss of episode 2599 = 19.93103\n","Loss of episode 2600 = 19.925148\n","Loss of episode 2601 = 19.928806\n","Loss of episode 2602 = 19.935211\n","Loss of episode 2603 = 19.925713\n","Loss of episode 2604 = 19.941273\n","Loss of episode 2605 = 19.931787\n","Loss of episode 2606 = 19.931253\n","Loss of episode 2607 = 19.948568\n","Loss of episode 2608 = 19.925636\n","Loss of episode 2609 = 19.945557\n","Loss of episode 2610 = 19.952835\n","Loss of episode 2611 = 19.928137\n","Loss of episode 2612 = 19.93566\n","Loss of episode 2613 = 19.962019\n","Loss of episode 2614 = 19.93327\n","Loss of episode 2615 = 19.958998\n","Loss of episode 2616 = 19.954369\n","Loss of episode 2617 = 19.932394\n","Loss of episode 2618 = 19.946356\n","Loss of episode 2619 = 19.93665\n","Loss of episode 2620 = 19.966866\n","Loss of episode 2621 = 19.94823\n","Loss of episode 2622 = 19.954266\n","Loss of episode 2623 = 19.973495\n","Loss of episode 2624 = 19.94869\n","Loss of episode 2625 = 19.955404\n","Loss of episode 2626 = 19.953678\n","Loss of episode 2627 = 19.94386\n","Loss of episode 2628 = 19.966007\n","Loss of episode 2629 = 19.928486\n","Loss of episode 2630 = 19.947466\n","Loss of episode 2631 = 19.95276\n","Loss of episode 2632 = 19.939753\n","Loss of episode 2633 = 19.946018\n","Loss of episode 2634 = 19.92488\n","Loss of episode 2635 = 19.926582\n","Loss of episode 2636 = 19.924618\n","Loss of episode 2637 = 19.917236\n","Loss of episode 2638 = 19.9048\n","Loss of episode 2639 = 19.896368\n","Loss of episode 2640 = 19.89948\n","Loss of episode 2641 = 19.897827\n","Loss of episode 2642 = 19.907135\n","Loss of episode 2643 = 19.913002\n","Loss of episode 2644 = 19.915527\n","Loss of episode 2645 = 19.90192\n","Loss of episode 2646 = 19.921192\n","Loss of episode 2647 = 19.922552\n","Loss of episode 2648 = 19.915365\n","Loss of episode 2649 = 19.940325\n","Loss of episode 2650 = 19.93081\n","Loss of episode 2651 = 19.925232\n","Loss of episode 2652 = 19.947647\n","Loss of episode 2653 = 19.948185\n","Loss of episode 2654 = 19.928482\n","Loss of episode 2655 = 19.958805\n","Loss of episode 2656 = 19.944221\n","Loss of episode 2657 = 19.937126\n","Loss of episode 2658 = 19.956547\n","Loss of episode 2659 = 19.931742\n","Loss of episode 2660 = 19.94434\n","Loss of episode 2661 = 19.953848\n","Loss of episode 2662 = 19.922207\n","Loss of episode 2663 = 19.958303\n","Loss of episode 2664 = 19.943577\n","Loss of episode 2665 = 19.924446\n","Loss of episode 2666 = 19.94279\n","Loss of episode 2667 = 19.935299\n","Loss of episode 2668 = 19.935751\n","Loss of episode 2669 = 19.969254\n","Loss of episode 2670 = 19.931324\n","Loss of episode 2671 = 19.935905\n","Loss of episode 2672 = 19.948626\n","Loss of episode 2673 = 19.915464\n","Loss of episode 2674 = 19.944817\n","Loss of episode 2675 = 19.913189\n","Loss of episode 2676 = 19.918201\n","Loss of episode 2677 = 19.925621\n","Loss of episode 2678 = 19.915136\n","Loss of episode 2679 = 19.926357\n","Loss of episode 2680 = 19.920998\n","Loss of episode 2681 = 19.897892\n","Loss of episode 2682 = 19.906927\n","Loss of episode 2683 = 19.929806\n","Loss of episode 2684 = 19.912848\n","Loss of episode 2685 = 19.93063\n","Loss of episode 2686 = 19.929688\n","Loss of episode 2687 = 19.91647\n","Loss of episode 2688 = 19.908688\n","Loss of episode 2689 = 19.917274\n","Loss of episode 2690 = 19.911034\n","Loss of episode 2691 = 19.929352\n","Loss of episode 2692 = 19.91047\n","Loss of episode 2693 = 19.936897\n","Loss of episode 2694 = 19.940151\n","Loss of episode 2695 = 19.931465\n","Loss of episode 2696 = 19.942686\n","Loss of episode 2697 = 19.935627\n","Loss of episode 2698 = 19.923605\n","Loss of episode 2699 = 19.93624\n","Loss of episode 2700 = 19.932682\n","Loss of episode 2701 = 19.91952\n","Loss of episode 2702 = 19.93333\n","Loss of episode 2703 = 19.94271\n","Loss of episode 2704 = 19.928398\n","Loss of episode 2705 = 19.94374\n","Loss of episode 2706 = 19.94614\n","Loss of episode 2707 = 19.943035\n","Loss of episode 2708 = 19.93713\n","Loss of episode 2709 = 19.94009\n","Loss of episode 2710 = 19.924019\n","Loss of episode 2711 = 19.942982\n","Loss of episode 2712 = 19.922134\n","Loss of episode 2713 = 19.932127\n","Loss of episode 2714 = 19.926102\n","Loss of episode 2715 = 19.917858\n","Loss of episode 2716 = 19.92778\n","Loss of episode 2717 = 19.939327\n","Loss of episode 2718 = 19.94269\n","Loss of episode 2719 = 19.964323\n","Loss of episode 2720 = 19.95619\n","Loss of episode 2721 = 19.950165\n","Loss of episode 2722 = 19.959618\n","Loss of episode 2723 = 19.955475\n","Loss of episode 2724 = 19.959644\n","Loss of episode 2725 = 19.991606\n","Loss of episode 2726 = 19.970297\n","Loss of episode 2727 = 19.998875\n","Loss of episode 2728 = 19.978325\n","Loss of episode 2729 = 19.957724\n","Loss of episode 2730 = 19.987484\n","Loss of episode 2731 = 19.962074\n","Loss of episode 2732 = 19.97161\n","Loss of episode 2733 = 19.956127\n","Loss of episode 2734 = 19.93248\n","Loss of episode 2735 = 19.944511\n","Loss of episode 2736 = 19.929384\n","Loss of episode 2737 = 19.929224\n","Loss of episode 2738 = 19.937483\n","Loss of episode 2739 = 19.919735\n","Loss of episode 2740 = 19.924519\n","Loss of episode 2741 = 19.927711\n","Loss of episode 2742 = 19.915398\n","Loss of episode 2743 = 19.921204\n","Loss of episode 2744 = 19.902088\n","Loss of episode 2745 = 19.908691\n","Loss of episode 2746 = 19.89901\n","Loss of episode 2747 = 19.907185\n","Loss of episode 2748 = 19.899742\n","Loss of episode 2749 = 19.89717\n","Loss of episode 2750 = 19.900566\n","Loss of episode 2751 = 19.894558\n","Loss of episode 2752 = 19.89037\n","Loss of episode 2753 = 19.878912\n","Loss of episode 2754 = 19.89249\n","Loss of episode 2755 = 19.879585\n","Loss of episode 2756 = 19.887693\n","Loss of episode 2757 = 19.899769\n","Loss of episode 2758 = 19.897226\n","Loss of episode 2759 = 19.893238\n","Loss of episode 2760 = 19.912415\n","Loss of episode 2761 = 19.905392\n","Loss of episode 2762 = 19.89586\n","Loss of episode 2763 = 19.914528\n","Loss of episode 2764 = 19.905582\n","Loss of episode 2765 = 19.898733\n","Loss of episode 2766 = 19.93346\n","Loss of episode 2767 = 19.932205\n","Loss of episode 2768 = 19.925768\n","Loss of episode 2769 = 19.948505\n","Loss of episode 2770 = 19.926395\n","Loss of episode 2771 = 19.95408\n","Loss of episode 2772 = 19.945766\n","Loss of episode 2773 = 19.932404\n","Loss of episode 2774 = 19.93557\n","Loss of episode 2775 = 19.924791\n","Loss of episode 2776 = 19.927856\n","Loss of episode 2777 = 19.91933\n","Loss of episode 2778 = 19.904325\n","Loss of episode 2779 = 19.922691\n","Loss of episode 2780 = 19.912003\n","Loss of episode 2781 = 19.885794\n","Loss of episode 2782 = 19.901142\n","Loss of episode 2783 = 19.909645\n","Loss of episode 2784 = 19.911915\n","Loss of episode 2785 = 19.909678\n","Loss of episode 2786 = 19.910011\n","Loss of episode 2787 = 19.911245\n","Loss of episode 2788 = 19.893692\n","Loss of episode 2789 = 19.911247\n","Loss of episode 2790 = 19.918964\n","Loss of episode 2791 = 19.9167\n","Loss of episode 2792 = 19.930267\n","Loss of episode 2793 = 19.924591\n","Loss of episode 2794 = 19.915514\n","Loss of episode 2795 = 19.9102\n","Loss of episode 2796 = 19.931911\n","Loss of episode 2797 = 19.925844\n","Loss of episode 2798 = 19.929712\n","Loss of episode 2799 = 19.93496\n","Loss of episode 2800 = 19.937237\n","Loss of episode 2801 = 19.928019\n","Loss of episode 2802 = 19.943943\n","Loss of episode 2803 = 19.9222\n","Loss of episode 2804 = 19.9207\n","Loss of episode 2805 = 19.93164\n","Loss of episode 2806 = 19.912615\n","Loss of episode 2807 = 19.919239\n","Loss of episode 2808 = 19.917063\n","Loss of episode 2809 = 19.902887\n","Loss of episode 2810 = 19.897877\n","Loss of episode 2811 = 19.905704\n","Loss of episode 2812 = 19.900656\n","Loss of episode 2813 = 19.905468\n","Loss of episode 2814 = 19.918856\n","Loss of episode 2815 = 19.928337\n","Loss of episode 2816 = 19.923676\n","Loss of episode 2817 = 19.91594\n","Loss of episode 2818 = 19.921017\n","Loss of episode 2819 = 19.92369\n","Loss of episode 2820 = 19.951004\n","Loss of episode 2821 = 19.935867\n","Loss of episode 2822 = 19.95683\n","Loss of episode 2823 = 19.956387\n","Loss of episode 2824 = 19.93681\n","Loss of episode 2825 = 19.955269\n","Loss of episode 2826 = 19.942703\n","Loss of episode 2827 = 19.942364\n","Loss of episode 2828 = 19.952585\n","Loss of episode 2829 = 19.917236\n","Loss of episode 2830 = 19.929623\n","Loss of episode 2831 = 19.9403\n","Loss of episode 2832 = 19.913685\n","Loss of episode 2833 = 19.928793\n","Loss of episode 2834 = 19.917826\n","Loss of episode 2835 = 19.914747\n","Loss of episode 2836 = 19.927687\n","Loss of episode 2837 = 19.925362\n","Loss of episode 2838 = 19.919027\n","Loss of episode 2839 = 19.94223\n","Loss of episode 2840 = 19.921436\n","Loss of episode 2841 = 19.922707\n","Loss of episode 2842 = 19.925213\n","Loss of episode 2843 = 19.934341\n","Loss of episode 2844 = 19.928112\n","Loss of episode 2845 = 19.931408\n","Loss of episode 2846 = 19.920551\n","Loss of episode 2847 = 19.932564\n","Loss of episode 2848 = 19.920868\n","Loss of episode 2849 = 19.938164\n","Loss of episode 2850 = 19.939491\n","Loss of episode 2851 = 19.926926\n","Loss of episode 2852 = 19.962132\n","Loss of episode 2853 = 19.939342\n","Loss of episode 2854 = 19.931492\n","Loss of episode 2855 = 19.971992\n","Loss of episode 2856 = 19.933182\n","Loss of episode 2857 = 19.953203\n","Loss of episode 2858 = 19.945\n","Loss of episode 2859 = 19.927818\n","Loss of episode 2860 = 19.94967\n","Loss of episode 2861 = 19.930866\n","Loss of episode 2862 = 19.941336\n","Loss of episode 2863 = 19.940578\n","Loss of episode 2864 = 19.912514\n","Loss of episode 2865 = 19.927784\n","Loss of episode 2866 = 19.91194\n","Loss of episode 2867 = 19.907385\n","Loss of episode 2868 = 19.9123\n","Loss of episode 2869 = 19.891228\n","Loss of episode 2870 = 19.894215\n","Loss of episode 2871 = 19.89932\n","Loss of episode 2872 = 19.90026\n","Loss of episode 2873 = 19.8936\n","Loss of episode 2874 = 19.877842\n","Loss of episode 2875 = 19.886816\n","Loss of episode 2876 = 19.884712\n","Loss of episode 2877 = 19.873383\n","Loss of episode 2878 = 19.878702\n","Loss of episode 2879 = 19.89194\n","Loss of episode 2880 = 19.879574\n","Loss of episode 2881 = 19.882086\n","Loss of episode 2882 = 19.873741\n","Loss of episode 2883 = 19.876389\n","Loss of episode 2884 = 19.884607\n","Loss of episode 2885 = 19.87335\n","Loss of episode 2886 = 19.866291\n","Loss of episode 2887 = 19.879234\n","Loss of episode 2888 = 19.875854\n","Loss of episode 2889 = 19.879293\n","Loss of episode 2890 = 19.880766\n","Loss of episode 2891 = 19.880978\n","Loss of episode 2892 = 19.896145\n","Loss of episode 2893 = 19.901318\n","Loss of episode 2894 = 19.889072\n","Loss of episode 2895 = 19.903152\n","Loss of episode 2896 = 19.89569\n","Loss of episode 2897 = 19.89935\n","Loss of episode 2898 = 19.912277\n","Loss of episode 2899 = 19.919987\n","Loss of episode 2900 = 19.90859\n","Loss of episode 2901 = 19.920698\n","Loss of episode 2902 = 19.909695\n","Loss of episode 2903 = 19.910109\n","Loss of episode 2904 = 19.913078\n","Loss of episode 2905 = 19.911528\n","Loss of episode 2906 = 19.91669\n","Loss of episode 2907 = 19.931328\n","Loss of episode 2908 = 19.915663\n","Loss of episode 2909 = 19.931635\n","Loss of episode 2910 = 19.929138\n","Loss of episode 2911 = 19.917501\n","Loss of episode 2912 = 19.943228\n","Loss of episode 2913 = 19.937351\n","Loss of episode 2914 = 19.907885\n","Loss of episode 2915 = 19.938513\n","Loss of episode 2916 = 19.929726\n","Loss of episode 2917 = 19.918251\n","Loss of episode 2918 = 19.940506\n","Loss of episode 2919 = 19.938686\n","Loss of episode 2920 = 19.922565\n","Loss of episode 2921 = 19.943703\n","Loss of episode 2922 = 19.919931\n","Loss of episode 2923 = 19.9197\n","Loss of episode 2924 = 19.929747\n","Loss of episode 2925 = 19.925968\n","Loss of episode 2926 = 19.937271\n","Loss of episode 2927 = 19.911873\n","Loss of episode 2928 = 19.915306\n","Loss of episode 2929 = 19.92754\n","Loss of episode 2930 = 19.906105\n","Loss of episode 2931 = 19.9206\n","Loss of episode 2932 = 19.924053\n","Loss of episode 2933 = 19.902227\n","Loss of episode 2934 = 19.931416\n","Loss of episode 2935 = 19.927555\n","Loss of episode 2936 = 19.911516\n","Loss of episode 2937 = 19.93015\n","Loss of episode 2938 = 19.920277\n","Loss of episode 2939 = 19.910664\n","Loss of episode 2940 = 19.927502\n","Loss of episode 2941 = 19.914461\n","Loss of episode 2942 = 19.909685\n","Loss of episode 2943 = 19.916374\n","Loss of episode 2944 = 19.904577\n","Loss of episode 2945 = 19.909504\n","Loss of episode 2946 = 19.924212\n","Loss of episode 2947 = 19.896545\n","Loss of episode 2948 = 19.90081\n","Loss of episode 2949 = 19.908901\n","Loss of episode 2950 = 19.912954\n","Loss of episode 2951 = 19.91624\n","Loss of episode 2952 = 19.922468\n","Loss of episode 2953 = 19.924864\n","Loss of episode 2954 = 19.932655\n","Loss of episode 2955 = 19.929039\n","Loss of episode 2956 = 19.916521\n","Loss of episode 2957 = 19.92302\n","Loss of episode 2958 = 19.926584\n","Loss of episode 2959 = 19.92773\n","Loss of episode 2960 = 19.902416\n","Loss of episode 2961 = 19.928806\n","Loss of episode 2962 = 19.919224\n","Loss of episode 2963 = 19.903595\n","Loss of episode 2964 = 19.913244\n","Loss of episode 2965 = 19.9085\n","Loss of episode 2966 = 19.902782\n","Loss of episode 2967 = 19.901495\n","Loss of episode 2968 = 19.895395\n","Loss of episode 2969 = 19.901073\n","Loss of episode 2970 = 19.896507\n","Loss of episode 2971 = 19.897947\n","Loss of episode 2972 = 19.890545\n","Loss of episode 2973 = 19.907581\n","Loss of episode 2974 = 19.901428\n","Loss of episode 2975 = 19.906143\n","Loss of episode 2976 = 19.894146\n","Loss of episode 2977 = 19.888878\n","Loss of episode 2978 = 19.897459\n","Loss of episode 2979 = 19.899454\n","Loss of episode 2980 = 19.896545\n","Loss of episode 2981 = 19.894695\n","Loss of episode 2982 = 19.892467\n","Loss of episode 2983 = 19.880875\n","Loss of episode 2984 = 19.8861\n","Loss of episode 2985 = 19.883835\n","Loss of episode 2986 = 19.882896\n","Loss of episode 2987 = 19.890587\n","Loss of episode 2988 = 19.893406\n","Loss of episode 2989 = 19.8913\n","Loss of episode 2990 = 19.906052\n","Loss of episode 2991 = 19.908773\n","Loss of episode 2992 = 19.89983\n","Loss of episode 2993 = 19.913443\n","Loss of episode 2994 = 19.904018\n","Loss of episode 2995 = 19.90596\n","Loss of episode 2996 = 19.91259\n","Loss of episode 2997 = 19.90196\n","Loss of episode 2998 = 19.913002\n","Loss of episode 2999 = 19.931961\n"]},{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0x1bea0f9f490>]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# feature_size, hidden_size, output_size\n","ODT = OnlineDesionTransformer(27,512,3).to(device)\n","num_epoch = 3000\n","Lambda = 1\n","# optimizer = torch.optim.SGD(net.parameters(),lr=0.5)\n","optimizer = torch.optim.Adam(ODT.parameters(),lr=0.001)\n","# loss_func = torch.nn.MSELoss() #使用均方差处理回归问题\n","loss_func = torch.nn.CrossEntropyLoss() #使用交叉熵处理分类问题\n","Loss=[]\n","for t in range(num_epoch):\n","    aver_loss = 0\n","    for batch, data in enumerate(data_train_loader):\n","        x, y, z = data\n","        # print(x.shape)\n","        prediction = ODT(x)\n","        # prediction = torch.transpose(prediction, dim0=0, dim1=1)\n","        Entropy = torch.mean(shannon_entropy(prediction))\n","        \n","        # add shannon entropy to encourage exploring\n","        loss = loss_func(prediction,y) - Lambda * Entropy \n","\n","        optimizer.zero_grad()\n","        loss.backward()   \n","        optimizer.step()   \n","        aver_loss += loss\n","    aver_loss /= batch\n","    aver_loss=aver_loss.cpu().detach().numpy()\n","    print('Loss of episode %s ='%t,aver_loss)\n","    Loss.append(aver_loss)\n","\n","plt.plot(Loss,color='r')"]},{"cell_type":"markdown","metadata":{"id":"S5bLRHqxFwGt"},"source":["## Training accuracy"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1690277764395,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"YQomTC-sFwGu"},"outputs":[{"name":"stdout","output_type":"stream","text":["acc = 0.846734375\n"]}],"source":["Truth = []\n","Pred = []\n","aver_loss = 0\n","total_acc = 0\n","for batch, data in enumerate(data_train_loader):\n","# for batch, data in enumerate(data_full_loader):\n","# for x,y in data_train_loader:\n","    x, y, _ = data\n","    # print(x)\n","    # prediction =net(x)\n","    test = ODT(x)\n","    # test = torch.transpose(test, dim0=0, dim1=1)\n","    # print(test)\n","    # print(y)\n","    # print(loss.data)\n","    # print(y[0])\n","    # print(test[0])\n","    a = torch.argmax(test,dim = 2).cpu().data.numpy()\n","    b = torch.argmax(y,dim = 2).cpu().data.numpy()\n","    # print(a)\n","    # print(b)\n","    # print(sum(a==b))\n","    aver_acc = sum(sum(a==b))/length\n","    # print(aver_acc)\n","    total_acc += aver_acc\n","    # print(total_acc)\n","    # print(aver_acc)\n","# print(batch)\n","print('acc =', total_acc/(0.8*max_number_traj))\n"]},{"cell_type":"markdown","metadata":{"id":"qxRq-IFIFwGu"},"source":["## Inference accuracy"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1690277764396,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"dNcwK2qJFwGu"},"outputs":[{"name":"stdout","output_type":"stream","text":["acc = 0.6459374999999996\n"]}],"source":["\n","Loss=[]\n","Truth = []\n","Pred = []\n","aver_loss = 0\n","total_acc = 0\n","for batch, data in enumerate(data_test_loader):\n","    x, y, _ = data\n","    ODT.eval()\n","    test = ODT(x)\n","    a = torch.argmax(test,dim = 2).cpu().data.numpy()\n","    b = torch.argmax(y,dim = 2).cpu().data.numpy()\n","    # print('-----------')\n","    # print('pred =',a[0])\n","    # print('true =',b[0])\n","    aver_acc = sum(a[0]==b[0])/length\n","    total_acc += aver_acc\n","print('acc =', total_acc/(0.2*max_number_traj))"]},{"cell_type":"markdown","metadata":{"id":"FjYyPM1JFwGv"},"source":["## AUC"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1690277764397,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"L0Fs56H7FwGv"},"outputs":[{"name":"stdout","output_type":"stream","text":["step 1 AUC = {0: 0.6694047619047618, 1: 0.6334124433803094, 2: 0.659253708167082}\n","step 2 AUC = {0: 0.7329800623587631, 1: 0.705419819971752, 2: 0.7125887445887445}\n","step 3 AUC = {0: 0.7522425081480199, 1: 0.7440124895861775, 2: 0.752158817154572}\n","step 4 AUC = {0: 0.7433945135477448, 1: 0.7626247189790194, 2: 0.7422559207006281}\n","step 5 AUC = {0: 0.7809841849914939, 1: 0.7978203037844332, 2: 0.7792953409651702}\n","step 6 AUC = {0: 0.8122640491856327, 1: 0.7868100864045142, 2: 0.7986642137848999}\n","step 7 AUC = {0: 0.8131324404761904, 1: 0.799659342531085, 2: 0.8163047619047619}\n","step 8 AUC = {0: 0.7837218694295901, 1: 0.7689278923919521, 2: 0.7906423361775226}\n","step 9 AUC = {0: 0.7829756976711442, 1: 0.7914852542512116, 2: 0.7991904182597613}\n","step 10 AUC = {0: 0.7719361881709554, 1: 0.8119434508601601, 2: 0.7965635688170775}\n","step 11 AUC = {0: 0.8053488486483827, 1: 0.8148771872176128, 2: 0.8267258833518385}\n","step 12 AUC = {0: 0.8150095238095239, 1: 0.8305861508520567, 2: 0.8046998932825705}\n","step 13 AUC = {0: 0.7705630509084368, 1: 0.8131239149305555, 2: 0.8141826285730664}\n","step 14 AUC = {0: 0.7988190724653772, 1: 0.7874276261373034, 2: 0.8096697039547368}\n","step 15 AUC = {0: 0.793837275921337, 1: 0.7888728851817615, 2: 0.7877347864042128}\n","step 16 AUC = {0: 0.8014106859460413, 1: 0.764371075126541, 2: 0.8079679535918449}\n","step 17 AUC = {0: 0.7993912018853102, 1: 0.8268346439552665, 2: 0.809170555604473}\n","step 18 AUC = {0: 0.7659530946922941, 1: 0.7957805736750342, 2: 0.780214165111526}\n","step 19 AUC = {0: 0.7683291071758104, 1: 0.755105131089383, 2: 0.798224185908193}\n","step 20 AUC = {0: 0.727721813897289, 1: 0.7429541887911946, 2: 0.7512899516452411}\n","Average AUC = [0.774471   0.77610246 0.78183988]\n"]}],"source":["from sklearn.metrics import precision_score, roc_curve, auc\n","n_classes = 3\n","\n","aver_auc = np.zeros(n_classes)\n","total_precision = 0\n","Y_score = np.zeros(((length, int(0.2*max_number_traj), n_classes)))\n","# print(Y_score.shape)\n","Y_label = np.zeros(((length, int(0.2*max_number_traj), n_classes)))\n","for batch, data in enumerate(data_test_loader):\n","    x, y, _ = data\n","    # print(x)\n","    test = ODT(x)\n","    y_score = test[0].cpu().data.numpy()\n","    y_label = y[0].cpu().data.numpy()\n","    # print(batch)\n","    for i in range(length):\n","        Y_score[i][batch] = y_score[i]\n","        Y_label[i][batch] = y_label[i]\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","aver_auc = np.zeros(n_classes)\n","for t in range(length):\n","    for i in range(n_classes):\n","        fpr[i], tpr[i], _ = roc_curve(Y_label[t][:, i], Y_score[t][:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","        # aver_auc[i] += auc(fpr[i], tpr[i])\n","        aver_auc[i] += roc_auc[i]/length\n","    print('step %s AUC ='%(t+1),roc_auc)\n","print('Average AUC =', aver_auc)\n","    # precision = precision_score(a,b, average=\"micro\")\n","    # total_precision += precision\n","# aver_precesion = total_precision/batch\n","# print(aver_precesion)\n","# print(aver_auc)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1690277764397,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"goUdJd2JFwGv"},"outputs":[],"source":["# aver_acc = np.zeros(length)\n","# for batch, data in enumerate(data_test_loader):\n","# # for batch, data in enumerate(data_full_loader):\n","# # for x,y in data_train_loader:\n","#     x, y = data\n","#     # print(x)\n","#     # prediction =net(x)\n","#     test = gru(x)\n","#     # print(test)\n","#     # print(y)\n","#     a = torch.argmax(test,dim = 2).cpu().data.numpy()\n","#     b = torch.argmax(y,dim = 2).cpu().data.numpy()\n","#     # print('-----------')\n","#     # print('predict =',a.T[0])\n","#     # print('true =',b[0])\n","#     for i in range(length):\n","#         aver_acc[i] += a.T[0][i]==b[0][i]\n","# aver_acc /= batch\n","# print('step acc =', aver_acc)\n","# print('aver acc =', sum(aver_acc)/length)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1690277764397,"user":{"displayName":"langming liu","userId":"10823962825404054022"},"user_tz":-480},"id":"a7I3q_2UFwGv"},"outputs":[{"name":"stdout","output_type":"stream","text":["Step 1: F1 = 0.5026 Precision = 0.5044 Recall = 0.5033\n","Step 2: F1 = 0.5599 Precision = 0.5618 Recall = 0.5603\n","Step 3: F1 = 0.6092 Precision = 0.6105 Recall = 0.6091\n","Step 4: F1 = 0.6017 Precision = 0.6037 Recall = 0.6026\n","Step 5: F1 = 0.6629 Precision = 0.6646 Recall = 0.6624\n","Step 6: F1 = 0.6532 Precision = 0.6582 Recall = 0.6557\n","Step 7: F1 = 0.6754 Precision = 0.6791 Recall = 0.6773\n","Step 8: F1 = 0.6504 Precision = 0.651 Recall = 0.651\n","Step 9: F1 = 0.6576 Precision = 0.66 Recall = 0.6584\n","Step 10: F1 = 0.6609 Precision = 0.6614 Recall = 0.6624\n","Step 11: F1 = 0.6939 Precision = 0.6939 Recall = 0.6952\n","Step 12: F1 = 0.705 Precision = 0.7054 Recall = 0.7054\n","Step 13: F1 = 0.6716 Precision = 0.6742 Recall = 0.6739\n","Step 14: F1 = 0.6864 Precision = 0.6939 Recall = 0.6882\n","Step 15: F1 = 0.6535 Precision = 0.6562 Recall = 0.6543\n","Step 16: F1 = 0.6625 Precision = 0.6632 Recall = 0.6626\n","Step 17: F1 = 0.6932 Precision = 0.6983 Recall = 0.6956\n","Step 18: F1 = 0.6461 Precision = 0.6499 Recall = 0.6485\n","Step 19: F1 = 0.659 Precision = 0.6611 Recall = 0.6597\n","Step 20: F1 = 0.6026 Precision = 0.6089 Recall = 0.6063\n","Aver_F1 = 0.6454 Aver_Precision = 0.648 Aver_Recall = 0.6466\n"]}],"source":["from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","aver_f1 = 0\n","aver_p = 0\n","aver_r = 0\n","\n","# print(y_pred)\n","# print(y_true)\n","for i in range(length):\n","  y_true = np.argmax(Y_label[i],axis = 1)\n","  y_pred = np.argmax(Y_score[i],axis = 1)\n","  f1 = round(f1_score(y_true, y_pred, average='macro' ),4)\n","  p = round(precision_score(y_true, y_pred, average='macro'),4)\n","  r = round(recall_score(y_true, y_pred, average='macro'),4)\n","  aver_f1 += f1/length\n","  aver_p += p/length\n","  aver_r += r/length\n","  print('Step %s:'%(i+1),'F1 =', f1, 'Precision =', p, 'Recall =', r)\n","print('Aver_F1 =', round(aver_f1,4), 'Aver_Precision =', round(aver_p,4), 'Aver_Recall =', round(aver_r,4))"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Policy_cost =  8000\n","Policy click number =  1914.0\n","Policy_CPC = 4.179728317659352\n"]}],"source":["\n","True_Click_matrix = np.zeros((800,20))\n","True_Action_matrix = np.zeros((800,20))\n","Click_pred_matrix = np.zeros((800,20))\n","Action_pred_matrix = np.zeros((800,20))\n","\n","# print(Click_pred_matrix)\n","\n","for batch, data in enumerate(data_test_loader):\n","# for batch, data in enumerate(data_full_loader):\n","# for x,y in data_train_loader:\n","    ODT.eval()\n","    x, y, z = data\n","    action_true = torch.squeeze(torch.argmax(y,dim = 2)).cpu().data.numpy()\n","    click_true = torch.squeeze(z).cpu().data.numpy()\n","    True_Click_matrix[batch] = click_true\n","    # True_Action_count += np.sum(action_true, axis = 0)\n","    \n","    action = ODT(x)\n","    action_pred = torch.squeeze(torch.argmax(action,dim = 2)).cpu().data.numpy()\n","    # print(action_true == action_pred)\n","    Action_pred_matrix[batch] = (action_true == action_pred)\n","    # click_pred = torch.squeeze(click).cpu().data.numpy()\n","    # Click_pred_matrix[batch] = click_pred\n","True_click = sum(sum(True_Click_matrix))\n","Cost = 8000\n","Click = sum(sum(Action_pred_matrix*True_Click_matrix))\n","cpc = Cost/Click\n","print('Policy_cost = ', Cost)\n","print('Policy click number = ', Click) \n","print('Policy_CPC =', cpc)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
